{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Mounting Google Drive**"
      ],
      "metadata": {
        "id": "_pFwECxG6EbF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3sXkauU87Fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be301c7d-804b-4961-ca0f-4e120aea500a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading Data**"
      ],
      "metadata": {
        "id": "lyIx2RAA6RA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "path = '/content/gdrive/MyDrive/Bathymetry/dataset_29SMD/02555_29SMD_20190314.npy'\n",
        "\n",
        "x = np.load(path)                                   #loading data from gdrive\n",
        "print(type(x))\n",
        "print('dimensions : ',x.ndim)\n",
        "print('shape : ', x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt-QXI61VgCl",
        "outputId": "9a751dbf-f225-41aa-cb85-80cefdab7fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "dimensions :  3\n",
            "shape :  (40, 40, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Displaying Image**"
      ],
      "metadata": {
        "id": "RxzZI9xE6eEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.fromarray((x*255).astype(np.uint8))       #converting a numpy array into Image\n",
        "im = im.convert('RGB')                               #converting each pixel to the triple 8-bit value \n",
        "final = Image.Image.split(im)                        #splitting the image into 3 individual bands\n",
        "plt.imshow(final[0])\n",
        "plt.show()\n",
        "plt.imshow(final[1])\n",
        "plt.show()\n",
        "plt.imshow(final[2])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0CmslmL8uZI",
        "outputId": "f08316ac-40ea-4fee-8329-3555ba7c0965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NN Model**"
      ],
      "metadata": {
        "id": "b_3pDbKazzmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required packages"
      ],
      "metadata": {
        "id": "A5wUguEBR3Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, concatenate, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rcdsOrKU24h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/Bathymetry'"
      ],
      "metadata": {
        "id": "kSOq4DHoR_GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting training data"
      ],
      "metadata": {
        "id": "KbfrO-eSR-s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = pd.read_csv(path + '/x_y_z_b2_b3_b4_b8_csv.csv')\n",
        "train_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NkJ6c5-7SGEm",
        "outputId": "ce0a479b-77d0-45af-b3e5-694bc74b8e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              x           y    elev    b2    b3    b4    b8     xrel     yrel\n",
              "0     453856.40  2613146.81  237.72  1203   930   620   429     0.00     0.00\n",
              "1     453846.17  2613145.40  237.73  1214   952   609   437   -10.23    -1.41\n",
              "2     453830.51  2613115.92  237.74  1205   945   615   420   -15.66   -29.48\n",
              "3     453886.47  2612795.40  237.75  1179   908   574   353    55.96  -320.52\n",
              "4     453828.02  2613083.49  237.76  1192   926   619   399   -58.45   288.09\n",
              "...         ...         ...     ...   ...   ...   ...   ...      ...      ...\n",
              "3968  455588.35  2601934.01  278.37  1160   922   660   442 -4125.74  8750.22\n",
              "3969  459726.09  2593190.54  278.38  1199   955   666   408  4137.74 -8743.47\n",
              "3970  456390.71  2599870.79  278.48  1165   919   636   420 -3335.38  6680.25\n",
              "3971  455593.88  2601925.54  278.50  1159   930   689   455  -796.83  2054.75\n",
              "3972  452996.58  2607000.88  278.87  1333  1100  1055  1075 -2597.30  5075.34\n",
              "\n",
              "[3973 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0e69f88-91fd-4b2c-abe2-9cfaf6bdb60a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>elev</th>\n",
              "      <th>b2</th>\n",
              "      <th>b3</th>\n",
              "      <th>b4</th>\n",
              "      <th>b8</th>\n",
              "      <th>xrel</th>\n",
              "      <th>yrel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>453856.40</td>\n",
              "      <td>2613146.81</td>\n",
              "      <td>237.72</td>\n",
              "      <td>1203</td>\n",
              "      <td>930</td>\n",
              "      <td>620</td>\n",
              "      <td>429</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>453846.17</td>\n",
              "      <td>2613145.40</td>\n",
              "      <td>237.73</td>\n",
              "      <td>1214</td>\n",
              "      <td>952</td>\n",
              "      <td>609</td>\n",
              "      <td>437</td>\n",
              "      <td>-10.23</td>\n",
              "      <td>-1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>453830.51</td>\n",
              "      <td>2613115.92</td>\n",
              "      <td>237.74</td>\n",
              "      <td>1205</td>\n",
              "      <td>945</td>\n",
              "      <td>615</td>\n",
              "      <td>420</td>\n",
              "      <td>-15.66</td>\n",
              "      <td>-29.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>453886.47</td>\n",
              "      <td>2612795.40</td>\n",
              "      <td>237.75</td>\n",
              "      <td>1179</td>\n",
              "      <td>908</td>\n",
              "      <td>574</td>\n",
              "      <td>353</td>\n",
              "      <td>55.96</td>\n",
              "      <td>-320.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>453828.02</td>\n",
              "      <td>2613083.49</td>\n",
              "      <td>237.76</td>\n",
              "      <td>1192</td>\n",
              "      <td>926</td>\n",
              "      <td>619</td>\n",
              "      <td>399</td>\n",
              "      <td>-58.45</td>\n",
              "      <td>288.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>455588.35</td>\n",
              "      <td>2601934.01</td>\n",
              "      <td>278.37</td>\n",
              "      <td>1160</td>\n",
              "      <td>922</td>\n",
              "      <td>660</td>\n",
              "      <td>442</td>\n",
              "      <td>-4125.74</td>\n",
              "      <td>8750.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>459726.09</td>\n",
              "      <td>2593190.54</td>\n",
              "      <td>278.38</td>\n",
              "      <td>1199</td>\n",
              "      <td>955</td>\n",
              "      <td>666</td>\n",
              "      <td>408</td>\n",
              "      <td>4137.74</td>\n",
              "      <td>-8743.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3970</th>\n",
              "      <td>456390.71</td>\n",
              "      <td>2599870.79</td>\n",
              "      <td>278.48</td>\n",
              "      <td>1165</td>\n",
              "      <td>919</td>\n",
              "      <td>636</td>\n",
              "      <td>420</td>\n",
              "      <td>-3335.38</td>\n",
              "      <td>6680.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3971</th>\n",
              "      <td>455593.88</td>\n",
              "      <td>2601925.54</td>\n",
              "      <td>278.50</td>\n",
              "      <td>1159</td>\n",
              "      <td>930</td>\n",
              "      <td>689</td>\n",
              "      <td>455</td>\n",
              "      <td>-796.83</td>\n",
              "      <td>2054.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>452996.58</td>\n",
              "      <td>2607000.88</td>\n",
              "      <td>278.87</td>\n",
              "      <td>1333</td>\n",
              "      <td>1100</td>\n",
              "      <td>1055</td>\n",
              "      <td>1075</td>\n",
              "      <td>-2597.30</td>\n",
              "      <td>5075.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3973 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0e69f88-91fd-4b2c-abe2-9cfaf6bdb60a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0e69f88-91fd-4b2c-abe2-9cfaf6bdb60a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0e69f88-91fd-4b2c-abe2-9cfaf6bdb60a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " mean_x = np.mean(train_list['x'])\n",
        " mean_y = np.mean(train_list['y'])\n",
        " train_list['xrel'] = train_list['x']-mean_x\n",
        " train_list['yrel'] = train_list['y']-mean_y\n",
        " train_list"
      ],
      "metadata": {
        "id": "YbIlYmXQSTkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "195a7575-ebc3-408f-b2f7-1f726936d9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              x           y    elev    b2    b3    b4    b8         xrel  \\\n",
              "0     453856.40  2613146.81  237.72  1203   930   620   429  -679.744855   \n",
              "1     453846.17  2613145.40  237.73  1214   952   609   437  -689.974855   \n",
              "2     453830.51  2613115.92  237.74  1205   945   615   420  -705.634855   \n",
              "3     453886.47  2612795.40  237.75  1179   908   574   353  -649.674855   \n",
              "4     453828.02  2613083.49  237.76  1192   926   619   399  -708.124855   \n",
              "...         ...         ...     ...   ...   ...   ...   ...          ...   \n",
              "3968  455588.35  2601934.01  278.37  1160   922   660   442  1052.205145   \n",
              "3969  459726.09  2593190.54  278.38  1199   955   666   408  5189.945145   \n",
              "3970  456390.71  2599870.79  278.48  1165   919   636   420  1854.565145   \n",
              "3971  455593.88  2601925.54  278.50  1159   930   689   455  1057.735145   \n",
              "3972  452996.58  2607000.88  278.87  1333  1100  1055  1075 -1539.564855   \n",
              "\n",
              "              yrel  \n",
              "0      5625.411314  \n",
              "1      5624.001314  \n",
              "2      5594.521314  \n",
              "3      5274.001314  \n",
              "4      5562.091314  \n",
              "...            ...  \n",
              "3968  -5587.388686  \n",
              "3969 -14330.858686  \n",
              "3970  -7650.608686  \n",
              "3971  -5595.858686  \n",
              "3972   -520.518686  \n",
              "\n",
              "[3973 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97f64e17-330a-494e-8b30-7ee17207fe8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>elev</th>\n",
              "      <th>b2</th>\n",
              "      <th>b3</th>\n",
              "      <th>b4</th>\n",
              "      <th>b8</th>\n",
              "      <th>xrel</th>\n",
              "      <th>yrel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>453856.40</td>\n",
              "      <td>2613146.81</td>\n",
              "      <td>237.72</td>\n",
              "      <td>1203</td>\n",
              "      <td>930</td>\n",
              "      <td>620</td>\n",
              "      <td>429</td>\n",
              "      <td>-679.744855</td>\n",
              "      <td>5625.411314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>453846.17</td>\n",
              "      <td>2613145.40</td>\n",
              "      <td>237.73</td>\n",
              "      <td>1214</td>\n",
              "      <td>952</td>\n",
              "      <td>609</td>\n",
              "      <td>437</td>\n",
              "      <td>-689.974855</td>\n",
              "      <td>5624.001314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>453830.51</td>\n",
              "      <td>2613115.92</td>\n",
              "      <td>237.74</td>\n",
              "      <td>1205</td>\n",
              "      <td>945</td>\n",
              "      <td>615</td>\n",
              "      <td>420</td>\n",
              "      <td>-705.634855</td>\n",
              "      <td>5594.521314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>453886.47</td>\n",
              "      <td>2612795.40</td>\n",
              "      <td>237.75</td>\n",
              "      <td>1179</td>\n",
              "      <td>908</td>\n",
              "      <td>574</td>\n",
              "      <td>353</td>\n",
              "      <td>-649.674855</td>\n",
              "      <td>5274.001314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>453828.02</td>\n",
              "      <td>2613083.49</td>\n",
              "      <td>237.76</td>\n",
              "      <td>1192</td>\n",
              "      <td>926</td>\n",
              "      <td>619</td>\n",
              "      <td>399</td>\n",
              "      <td>-708.124855</td>\n",
              "      <td>5562.091314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>455588.35</td>\n",
              "      <td>2601934.01</td>\n",
              "      <td>278.37</td>\n",
              "      <td>1160</td>\n",
              "      <td>922</td>\n",
              "      <td>660</td>\n",
              "      <td>442</td>\n",
              "      <td>1052.205145</td>\n",
              "      <td>-5587.388686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>459726.09</td>\n",
              "      <td>2593190.54</td>\n",
              "      <td>278.38</td>\n",
              "      <td>1199</td>\n",
              "      <td>955</td>\n",
              "      <td>666</td>\n",
              "      <td>408</td>\n",
              "      <td>5189.945145</td>\n",
              "      <td>-14330.858686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3970</th>\n",
              "      <td>456390.71</td>\n",
              "      <td>2599870.79</td>\n",
              "      <td>278.48</td>\n",
              "      <td>1165</td>\n",
              "      <td>919</td>\n",
              "      <td>636</td>\n",
              "      <td>420</td>\n",
              "      <td>1854.565145</td>\n",
              "      <td>-7650.608686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3971</th>\n",
              "      <td>455593.88</td>\n",
              "      <td>2601925.54</td>\n",
              "      <td>278.50</td>\n",
              "      <td>1159</td>\n",
              "      <td>930</td>\n",
              "      <td>689</td>\n",
              "      <td>455</td>\n",
              "      <td>1057.735145</td>\n",
              "      <td>-5595.858686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>452996.58</td>\n",
              "      <td>2607000.88</td>\n",
              "      <td>278.87</td>\n",
              "      <td>1333</td>\n",
              "      <td>1100</td>\n",
              "      <td>1055</td>\n",
              "      <td>1075</td>\n",
              "      <td>-1539.564855</td>\n",
              "      <td>-520.518686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3973 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97f64e17-330a-494e-8b30-7ee17207fe8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97f64e17-330a-494e-8b30-7ee17207fe8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97f64e17-330a-494e-8b30-7ee17207fe8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = train_list[['b2','b3','b4','b8']]\n",
        "labels = train_list['elev']\n",
        "print(training)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0PbvH2NSonH",
        "outputId": "141c85bc-6ded-47e1-b825-2e81e3c6dc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        b2    b3    b4    b8\n",
            "0     1203   930   620   429\n",
            "1     1214   952   609   437\n",
            "2     1205   945   615   420\n",
            "3     1179   908   574   353\n",
            "4     1192   926   619   399\n",
            "...    ...   ...   ...   ...\n",
            "3968  1160   922   660   442\n",
            "3969  1199   955   666   408\n",
            "3970  1165   919   636   420\n",
            "3971  1159   930   689   455\n",
            "3972  1333  1100  1055  1075\n",
            "\n",
            "[3973 rows x 4 columns]\n",
            "0       237.72\n",
            "1       237.73\n",
            "2       237.74\n",
            "3       237.75\n",
            "4       237.76\n",
            "         ...  \n",
            "3968    278.37\n",
            "3969    278.38\n",
            "3970    278.48\n",
            "3971    278.50\n",
            "3972    278.87\n",
            "Name: elev, Length: 3973, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HiAtg5lNTov",
        "outputId": "13fc3420-e9ab-4bed-a239-1a503dec3de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.asarray(labels).reshape(-1,1)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvVYEYFESxrb",
        "outputId": "657161d2-83b8-4c7a-e4cd-b3c0eced9249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[237.72],\n",
              "       [237.73],\n",
              "       [237.74],\n",
              "       ...,\n",
              "       [278.48],\n",
              "       [278.5 ],\n",
              "       [278.87]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# # min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# # training = min_max_scaler.fit_transform(training)\n",
        "# # lab_mean = np.mean(labels)\n",
        "# # lab_var = np.var(labels)\n",
        "# # labels = (labels- lab_mean)/lab_var\n",
        "\n",
        "# scaler_x = MinMaxScaler()\n",
        "# scaler_y = MinMaxScaler()\n",
        "# print(scaler_x.fit(training))\n",
        "# training=scaler_x.transform(training)\n",
        "# print(training)\n",
        "# print(scaler_y.fit(labels))\n",
        "# labels=scaler_y.transform(labels)\n",
        "# print(labels)"
      ],
      "metadata": {
        "id": "LQQp4lT5S5zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training=pd.DataFrame(training,columns=['b2','b3','b4','b8'])\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(training, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)\n",
        "\n",
        "print(np.shape(X_train),'\\n',np.shape(y_train),'\\n',np.shape(X_test),'\\n',np.shape(y_test),'\\n',np.shape(X_valid),'\\n',np.shape(y_valid))\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL8ZLC7YS-iI",
        "outputId": "8e9cb287-a49a-463c-effd-0be6641bf8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2781, 4) \n",
            " (2781,) \n",
            " (596, 4) \n",
            " (596,) \n",
            " (596, 4) \n",
            " (596,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_for_nan = X_test['b2'].isnull().values.any()\n",
        "print (check_for_nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtoALB6aTCqK",
        "outputId": "2aba4091-e982-4e58-8a6e-b62afe764f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim=4, activation='relu'))\n",
        "# model.add(Dense(8, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# model.add(Dense(12, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
        "# model.add(Dense(8, activation='relu'))\n",
        "# model.add(Dense(1, activation='linear'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u54aNznTFIV",
        "outputId": "80d937dd-4c86-468a-98be-c6d55ae49f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                112       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359\n",
            "Trainable params: 1,359\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(0.01)\n",
        "model.compile(loss='mse', optimizer=adam, metrics='mse')"
      ],
      "metadata": {
        "id": "n936vpj-TKDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, batch_size=512,  verbose=1, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "Svb28vh3HuVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdb5f9a-ae24-471f-d4ea-94ea216c900d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 1s 69ms/step - loss: 61736.1680 - mse: 61736.1680 - val_loss: 21137.9082 - val_mse: 21137.9082\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11446.7061 - mse: 11446.7061 - val_loss: 2994.2700 - val_mse: 2994.2700\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2934.2761 - mse: 2934.2761 - val_loss: 6088.7129 - val_mse: 6088.7129\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2920.6504 - mse: 2920.6504 - val_loss: 1750.5085 - val_mse: 1750.5085\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1893.1510 - mse: 1893.1510 - val_loss: 245.0829 - val_mse: 245.0829\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 998.3481 - mse: 998.3481 - val_loss: 501.2662 - val_mse: 501.2662\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 462.5556 - mse: 462.5556 - val_loss: 679.6071 - val_mse: 679.6071\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 358.8849 - mse: 358.8849 - val_loss: 421.5437 - val_mse: 421.5437\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 326.4227 - mse: 326.4227 - val_loss: 280.8372 - val_mse: 280.8372\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 283.5767 - mse: 283.5767 - val_loss: 181.9287 - val_mse: 181.9287\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 234.1952 - mse: 234.1952 - val_loss: 172.0614 - val_mse: 172.0614\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 207.8267 - mse: 207.8267 - val_loss: 175.6565 - val_mse: 175.6565\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 193.8915 - mse: 193.8915 - val_loss: 169.6744 - val_mse: 169.6744\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 185.9670 - mse: 185.9670 - val_loss: 175.3773 - val_mse: 175.3773\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 183.8846 - mse: 183.8846 - val_loss: 165.1403 - val_mse: 165.1403\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 178.8924 - mse: 178.8924 - val_loss: 166.5870 - val_mse: 166.5870\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 175.1657 - mse: 175.1657 - val_loss: 161.4319 - val_mse: 161.4319\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 173.3390 - mse: 173.3390 - val_loss: 160.9052 - val_mse: 160.9052\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 170.7183 - mse: 170.7183 - val_loss: 158.9886 - val_mse: 158.9886\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 168.1644 - mse: 168.1644 - val_loss: 157.3995 - val_mse: 157.3995\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 165.5147 - mse: 165.5147 - val_loss: 155.3935 - val_mse: 155.3935\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 163.4161 - mse: 163.4161 - val_loss: 154.6989 - val_mse: 154.6989\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 161.4480 - mse: 161.4480 - val_loss: 152.5280 - val_mse: 152.5280\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 159.4849 - mse: 159.4849 - val_loss: 152.2503 - val_mse: 152.2503\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 158.0634 - mse: 158.0634 - val_loss: 149.2017 - val_mse: 149.2017\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 156.6537 - mse: 156.6537 - val_loss: 151.2576 - val_mse: 151.2576\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 154.3480 - mse: 154.3480 - val_loss: 146.3152 - val_mse: 146.3152\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 152.3885 - mse: 152.3885 - val_loss: 146.5863 - val_mse: 146.5863\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 150.4000 - mse: 150.4000 - val_loss: 143.6401 - val_mse: 143.6401\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 148.8444 - mse: 148.8444 - val_loss: 142.4503 - val_mse: 142.4503\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 146.7756 - mse: 146.7756 - val_loss: 141.5078 - val_mse: 141.5078\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 145.1630 - mse: 145.1630 - val_loss: 141.0287 - val_mse: 141.0287\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 143.7481 - mse: 143.7481 - val_loss: 139.0569 - val_mse: 139.0569\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 142.4395 - mse: 142.4395 - val_loss: 137.4765 - val_mse: 137.4765\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 140.8344 - mse: 140.8344 - val_loss: 138.5604 - val_mse: 138.5604\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 139.6535 - mse: 139.6535 - val_loss: 135.2985 - val_mse: 135.2985\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 137.6774 - mse: 137.6774 - val_loss: 134.6805 - val_mse: 134.6805\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 136.9491 - mse: 136.9491 - val_loss: 135.1396 - val_mse: 135.1396\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 135.4384 - mse: 135.4384 - val_loss: 132.0969 - val_mse: 132.0969\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 133.8143 - mse: 133.8143 - val_loss: 132.2529 - val_mse: 132.2529\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 132.2649 - mse: 132.2649 - val_loss: 130.1569 - val_mse: 130.1569\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 131.4165 - mse: 131.4165 - val_loss: 132.3272 - val_mse: 132.3272\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 130.6760 - mse: 130.6760 - val_loss: 128.1573 - val_mse: 128.1573\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 129.7319 - mse: 129.7319 - val_loss: 127.2286 - val_mse: 127.2286\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 128.0434 - mse: 128.0434 - val_loss: 128.4403 - val_mse: 128.4403\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 127.7363 - mse: 127.7363 - val_loss: 126.7254 - val_mse: 126.7254\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 126.8593 - mse: 126.8593 - val_loss: 125.3750 - val_mse: 125.3750\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 125.7190 - mse: 125.7190 - val_loss: 125.0427 - val_mse: 125.0427\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 124.0921 - mse: 124.0921 - val_loss: 122.9860 - val_mse: 122.9860\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 123.0633 - mse: 123.0633 - val_loss: 122.2821 - val_mse: 122.2821\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 122.6701 - mse: 122.6701 - val_loss: 124.1964 - val_mse: 124.1964\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 122.4767 - mse: 122.4767 - val_loss: 120.7353 - val_mse: 120.7353\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 120.0955 - mse: 120.0955 - val_loss: 120.2914 - val_mse: 120.2914\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 119.1778 - mse: 119.1778 - val_loss: 119.5684 - val_mse: 119.5684\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 118.9167 - mse: 118.9167 - val_loss: 118.8387 - val_mse: 118.8387\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 117.9412 - mse: 117.9412 - val_loss: 119.8442 - val_mse: 119.8442\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 117.2385 - mse: 117.2385 - val_loss: 117.3913 - val_mse: 117.3913\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 116.4614 - mse: 116.4614 - val_loss: 116.7645 - val_mse: 116.7645\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 115.4483 - mse: 115.4483 - val_loss: 116.9793 - val_mse: 116.9793\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.8889 - mse: 114.8889 - val_loss: 115.6627 - val_mse: 115.6627\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.5576 - mse: 114.5576 - val_loss: 115.1826 - val_mse: 115.1826\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 114.5209 - mse: 114.5209 - val_loss: 117.6586 - val_mse: 117.6586\n",
            "Epoch 63/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 113.6757 - mse: 113.6757 - val_loss: 113.9649 - val_mse: 113.9649\n",
            "Epoch 64/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 112.3316 - mse: 112.3316 - val_loss: 113.4080 - val_mse: 113.4080\n",
            "Epoch 65/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 112.2847 - mse: 112.2847 - val_loss: 113.0336 - val_mse: 113.0336\n",
            "Epoch 66/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 112.1791 - mse: 112.1791 - val_loss: 117.7575 - val_mse: 117.7575\n",
            "Epoch 67/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 112.4116 - mse: 112.4116 - val_loss: 111.9492 - val_mse: 111.9492\n",
            "Epoch 68/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 111.0240 - mse: 111.0240 - val_loss: 114.6972 - val_mse: 114.6972\n",
            "Epoch 69/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 111.9276 - mse: 111.9276 - val_loss: 112.6591 - val_mse: 112.6591\n",
            "Epoch 70/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 110.8597 - mse: 110.8597 - val_loss: 114.7378 - val_mse: 114.7378\n",
            "Epoch 71/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 111.4212 - mse: 111.4212 - val_loss: 110.1343 - val_mse: 110.1343\n",
            "Epoch 72/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 108.8400 - mse: 108.8400 - val_loss: 109.7099 - val_mse: 109.7099\n",
            "Epoch 73/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 107.8499 - mse: 107.8499 - val_loss: 109.2670 - val_mse: 109.2670\n",
            "Epoch 74/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 107.2703 - mse: 107.2703 - val_loss: 112.4283 - val_mse: 112.4283\n",
            "Epoch 75/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 108.3680 - mse: 108.3680 - val_loss: 108.4819 - val_mse: 108.4819\n",
            "Epoch 76/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 106.8306 - mse: 106.8306 - val_loss: 108.3948 - val_mse: 108.3948\n",
            "Epoch 77/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 106.2277 - mse: 106.2277 - val_loss: 107.8217 - val_mse: 107.8217\n",
            "Epoch 78/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.8991 - mse: 105.8991 - val_loss: 107.3698 - val_mse: 107.3698\n",
            "Epoch 79/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.5844 - mse: 105.5844 - val_loss: 107.0241 - val_mse: 107.0241\n",
            "Epoch 80/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.0976 - mse: 105.0976 - val_loss: 106.7909 - val_mse: 106.7909\n",
            "Epoch 81/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 104.8584 - mse: 104.8584 - val_loss: 106.4366 - val_mse: 106.4366\n",
            "Epoch 82/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 104.5175 - mse: 104.5175 - val_loss: 106.0398 - val_mse: 106.0398\n",
            "Epoch 83/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 104.3113 - mse: 104.3113 - val_loss: 105.7259 - val_mse: 105.7259\n",
            "Epoch 84/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.9531 - mse: 103.9531 - val_loss: 106.6164 - val_mse: 106.6164\n",
            "Epoch 85/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 104.2340 - mse: 104.2340 - val_loss: 105.9116 - val_mse: 105.9116\n",
            "Epoch 86/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.5431 - mse: 103.5431 - val_loss: 105.6455 - val_mse: 105.6455\n",
            "Epoch 87/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.5722 - mse: 103.5722 - val_loss: 104.5748 - val_mse: 104.5748\n",
            "Epoch 88/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.7617 - mse: 102.7617 - val_loss: 104.2815 - val_mse: 104.2815\n",
            "Epoch 89/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.0934 - mse: 103.0934 - val_loss: 104.4773 - val_mse: 104.4773\n",
            "Epoch 90/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 102.3675 - mse: 102.3675 - val_loss: 103.7716 - val_mse: 103.7716\n",
            "Epoch 91/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.3963 - mse: 102.3963 - val_loss: 105.4029 - val_mse: 105.4029\n",
            "Epoch 92/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.5752 - mse: 103.5752 - val_loss: 116.6129 - val_mse: 116.6129\n",
            "Epoch 93/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 108.9669 - mse: 108.9669 - val_loss: 103.1363 - val_mse: 103.1363\n",
            "Epoch 94/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 102.9324 - mse: 102.9324 - val_loss: 108.5397 - val_mse: 108.5397\n",
            "Epoch 95/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.2083 - mse: 104.2083 - val_loss: 103.3961 - val_mse: 103.3961\n",
            "Epoch 96/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 102.6885 - mse: 102.6885 - val_loss: 102.4025 - val_mse: 102.4025\n",
            "Epoch 97/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 101.4910 - mse: 101.4910 - val_loss: 102.6933 - val_mse: 102.6933\n",
            "Epoch 98/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.9670 - mse: 100.9670 - val_loss: 102.8226 - val_mse: 102.8226\n",
            "Epoch 99/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.7876 - mse: 100.7876 - val_loss: 102.5932 - val_mse: 102.5932\n",
            "Epoch 100/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.6051 - mse: 100.6051 - val_loss: 101.5739 - val_mse: 101.5739\n",
            "Epoch 101/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.0905 - mse: 100.0905 - val_loss: 102.9398 - val_mse: 102.9398\n",
            "Epoch 102/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.1617 - mse: 100.1617 - val_loss: 103.1424 - val_mse: 103.1424\n",
            "Epoch 103/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.6974 - mse: 100.6974 - val_loss: 102.9716 - val_mse: 102.9716\n",
            "Epoch 104/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.8801 - mse: 101.8801 - val_loss: 101.0166 - val_mse: 101.0166\n",
            "Epoch 105/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 101.1700 - mse: 101.1700 - val_loss: 101.7489 - val_mse: 101.7489\n",
            "Epoch 106/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.6443 - mse: 100.6443 - val_loss: 100.8152 - val_mse: 100.8152\n",
            "Epoch 107/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.2308 - mse: 99.2308 - val_loss: 101.0051 - val_mse: 101.0051\n",
            "Epoch 108/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.3529 - mse: 100.3529 - val_loss: 100.5435 - val_mse: 100.5435\n",
            "Epoch 109/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.1503 - mse: 99.1503 - val_loss: 100.0340 - val_mse: 100.0340\n",
            "Epoch 110/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.9841 - mse: 98.9841 - val_loss: 100.3263 - val_mse: 100.3263\n",
            "Epoch 111/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0237 - mse: 99.0237 - val_loss: 100.0501 - val_mse: 100.0501\n",
            "Epoch 112/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.9607 - mse: 98.9607 - val_loss: 100.0193 - val_mse: 100.0193\n",
            "Epoch 113/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0397 - mse: 99.0397 - val_loss: 99.6993 - val_mse: 99.6993\n",
            "Epoch 114/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.4513 - mse: 98.4513 - val_loss: 99.4071 - val_mse: 99.4071\n",
            "Epoch 115/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.5022 - mse: 98.5022 - val_loss: 100.8742 - val_mse: 100.8742\n",
            "Epoch 116/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.8328 - mse: 98.8328 - val_loss: 99.0931 - val_mse: 99.0931\n",
            "Epoch 117/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.2528 - mse: 98.2528 - val_loss: 99.2096 - val_mse: 99.2096\n",
            "Epoch 118/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.6959 - mse: 98.6959 - val_loss: 99.0560 - val_mse: 99.0560\n",
            "Epoch 119/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.0607 - mse: 99.0607 - val_loss: 98.7631 - val_mse: 98.7631\n",
            "Epoch 120/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.8736 - mse: 97.8736 - val_loss: 98.8092 - val_mse: 98.8092\n",
            "Epoch 121/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.6828 - mse: 99.6828 - val_loss: 98.7596 - val_mse: 98.7596\n",
            "Epoch 122/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0800 - mse: 99.0800 - val_loss: 100.0453 - val_mse: 100.0453\n",
            "Epoch 123/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.8973 - mse: 98.8973 - val_loss: 98.3396 - val_mse: 98.3396\n",
            "Epoch 124/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.8218 - mse: 97.8218 - val_loss: 98.2070 - val_mse: 98.2070\n",
            "Epoch 125/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.8374 - mse: 97.8374 - val_loss: 98.8932 - val_mse: 98.8932\n",
            "Epoch 126/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.4432 - mse: 98.4432 - val_loss: 101.1502 - val_mse: 101.1502\n",
            "Epoch 127/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.2070 - mse: 99.2070 - val_loss: 99.9781 - val_mse: 99.9781\n",
            "Epoch 128/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.5997 - mse: 99.5997 - val_loss: 99.2432 - val_mse: 99.2432\n",
            "Epoch 129/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.9322 - mse: 98.9322 - val_loss: 97.7577 - val_mse: 97.7577\n",
            "Epoch 130/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0100 - mse: 99.0100 - val_loss: 99.2696 - val_mse: 99.2696\n",
            "Epoch 131/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.3532 - mse: 98.3532 - val_loss: 98.3016 - val_mse: 98.3016\n",
            "Epoch 132/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 97.6926 - mse: 97.6926 - val_loss: 101.2603 - val_mse: 101.2603\n",
            "Epoch 133/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.7074 - mse: 100.7074 - val_loss: 101.9909 - val_mse: 101.9909\n",
            "Epoch 134/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.4215 - mse: 98.4215 - val_loss: 101.3169 - val_mse: 101.3169\n",
            "Epoch 135/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0417 - mse: 99.0417 - val_loss: 99.9083 - val_mse: 99.9083\n",
            "Epoch 136/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.2011 - mse: 99.2011 - val_loss: 101.7173 - val_mse: 101.7173\n",
            "Epoch 137/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.2513 - mse: 99.2513 - val_loss: 97.6832 - val_mse: 97.6832\n",
            "Epoch 138/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.9019 - mse: 98.9019 - val_loss: 97.7313 - val_mse: 97.7313\n",
            "Epoch 139/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.9028 - mse: 97.9028 - val_loss: 97.2426 - val_mse: 97.2426\n",
            "Epoch 140/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.0617 - mse: 97.0617 - val_loss: 96.9747 - val_mse: 96.9747\n",
            "Epoch 141/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.0130 - mse: 98.0130 - val_loss: 99.7028 - val_mse: 99.7028\n",
            "Epoch 142/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.6675 - mse: 97.6675 - val_loss: 96.8744 - val_mse: 96.8744\n",
            "Epoch 143/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1046 - mse: 98.1046 - val_loss: 98.1474 - val_mse: 98.1474\n",
            "Epoch 144/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.2422 - mse: 98.2422 - val_loss: 97.3953 - val_mse: 97.3953\n",
            "Epoch 145/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.1387 - mse: 97.1387 - val_loss: 97.8941 - val_mse: 97.8941\n",
            "Epoch 146/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.1686 - mse: 98.1686 - val_loss: 100.8250 - val_mse: 100.8250\n",
            "Epoch 147/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.8034 - mse: 98.8034 - val_loss: 98.0056 - val_mse: 98.0056\n",
            "Epoch 148/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.0152 - mse: 97.0152 - val_loss: 96.5523 - val_mse: 96.5523\n",
            "Epoch 149/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 97.0042 - mse: 97.0042 - val_loss: 96.6823 - val_mse: 96.6823\n",
            "Epoch 150/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.0340 - mse: 97.0340 - val_loss: 96.6835 - val_mse: 96.6835\n",
            "Epoch 151/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.2196 - mse: 97.2196 - val_loss: 96.5072 - val_mse: 96.5072\n",
            "Epoch 152/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.9505 - mse: 96.9505 - val_loss: 96.6560 - val_mse: 96.6560\n",
            "Epoch 153/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.8745 - mse: 96.8745 - val_loss: 100.4370 - val_mse: 100.4370\n",
            "Epoch 154/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.0963 - mse: 99.0963 - val_loss: 99.1312 - val_mse: 99.1312\n",
            "Epoch 155/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.2245 - mse: 100.2245 - val_loss: 99.4970 - val_mse: 99.4970\n",
            "Epoch 156/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.0440 - mse: 101.0440 - val_loss: 98.0620 - val_mse: 98.0620\n",
            "Epoch 157/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.3554 - mse: 98.3554 - val_loss: 98.9951 - val_mse: 98.9951\n",
            "Epoch 158/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.1629 - mse: 98.1629 - val_loss: 98.1455 - val_mse: 98.1455\n",
            "Epoch 159/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1687 - mse: 98.1687 - val_loss: 98.2591 - val_mse: 98.2591\n",
            "Epoch 160/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.7853 - mse: 100.7853 - val_loss: 96.2648 - val_mse: 96.2648\n",
            "Epoch 161/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 101.0850 - mse: 101.0850 - val_loss: 97.2744 - val_mse: 97.2744\n",
            "Epoch 162/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.6954 - mse: 98.6954 - val_loss: 97.0536 - val_mse: 97.0536\n",
            "Epoch 163/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.5929 - mse: 97.5929 - val_loss: 95.9804 - val_mse: 95.9804\n",
            "Epoch 164/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.5182 - mse: 98.5182 - val_loss: 102.0913 - val_mse: 102.0913\n",
            "Epoch 165/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.6499 - mse: 99.6499 - val_loss: 103.8599 - val_mse: 103.8599\n",
            "Epoch 166/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.3321 - mse: 100.3321 - val_loss: 102.5423 - val_mse: 102.5423\n",
            "Epoch 167/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.2035 - mse: 99.2035 - val_loss: 101.7224 - val_mse: 101.7224\n",
            "Epoch 168/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.2234 - mse: 99.2234 - val_loss: 97.7665 - val_mse: 97.7665\n",
            "Epoch 169/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.0826 - mse: 98.0826 - val_loss: 95.8893 - val_mse: 95.8893\n",
            "Epoch 170/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.5077 - mse: 98.5077 - val_loss: 96.0670 - val_mse: 96.0670\n",
            "Epoch 171/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.6553 - mse: 97.6553 - val_loss: 96.4616 - val_mse: 96.4616\n",
            "Epoch 172/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.3156 - mse: 98.3156 - val_loss: 100.6033 - val_mse: 100.6033\n",
            "Epoch 173/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.3484 - mse: 101.3484 - val_loss: 100.5634 - val_mse: 100.5634\n",
            "Epoch 174/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.2396 - mse: 99.2396 - val_loss: 101.3144 - val_mse: 101.3144\n",
            "Epoch 175/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.5160 - mse: 100.5160 - val_loss: 98.9114 - val_mse: 98.9114\n",
            "Epoch 176/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0723 - mse: 99.0723 - val_loss: 97.1819 - val_mse: 97.1819\n",
            "Epoch 177/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.5296 - mse: 99.5296 - val_loss: 98.7479 - val_mse: 98.7479\n",
            "Epoch 178/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.8398 - mse: 97.8398 - val_loss: 95.9838 - val_mse: 95.9838\n",
            "Epoch 179/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.9960 - mse: 96.9960 - val_loss: 95.8928 - val_mse: 95.8928\n",
            "Epoch 180/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.4020 - mse: 97.4020 - val_loss: 95.4917 - val_mse: 95.4917\n",
            "Epoch 181/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.4635 - mse: 96.4635 - val_loss: 95.4951 - val_mse: 95.4951\n",
            "Epoch 182/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.0067 - mse: 97.0067 - val_loss: 96.0385 - val_mse: 96.0385\n",
            "Epoch 183/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.5100 - mse: 99.5100 - val_loss: 98.7772 - val_mse: 98.7772\n",
            "Epoch 184/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.0787 - mse: 97.0787 - val_loss: 100.6550 - val_mse: 100.6550\n",
            "Epoch 185/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.2575 - mse: 100.2575 - val_loss: 97.2168 - val_mse: 97.2168\n",
            "Epoch 186/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.5242 - mse: 98.5242 - val_loss: 96.1075 - val_mse: 96.1075\n",
            "Epoch 187/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.9145 - mse: 96.9145 - val_loss: 95.4409 - val_mse: 95.4409\n",
            "Epoch 188/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.4239 - mse: 96.4239 - val_loss: 95.6738 - val_mse: 95.6738\n",
            "Epoch 189/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.1338 - mse: 97.1338 - val_loss: 95.4534 - val_mse: 95.4534\n",
            "Epoch 190/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.2737 - mse: 97.2737 - val_loss: 95.5121 - val_mse: 95.5121\n",
            "Epoch 191/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.9411 - mse: 96.9411 - val_loss: 95.5616 - val_mse: 95.5616\n",
            "Epoch 192/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.4567 - mse: 96.4567 - val_loss: 96.5661 - val_mse: 96.5661\n",
            "Epoch 193/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.9912 - mse: 96.9912 - val_loss: 96.1581 - val_mse: 96.1581\n",
            "Epoch 194/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.6034 - mse: 97.6034 - val_loss: 96.7467 - val_mse: 96.7467\n",
            "Epoch 195/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.5070 - mse: 96.5070 - val_loss: 95.6900 - val_mse: 95.6900\n",
            "Epoch 196/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.8754 - mse: 96.8754 - val_loss: 95.7929 - val_mse: 95.7929\n",
            "Epoch 197/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.6632 - mse: 96.6632 - val_loss: 100.3122 - val_mse: 100.3122\n",
            "Epoch 198/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.7420 - mse: 99.7420 - val_loss: 123.2896 - val_mse: 123.2896\n",
            "Epoch 199/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 114.0410 - mse: 114.0410 - val_loss: 103.6408 - val_mse: 103.6408\n",
            "Epoch 200/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 109.6169 - mse: 109.6169 - val_loss: 98.4181 - val_mse: 98.4181\n",
            "Epoch 201/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.8911 - mse: 105.8911 - val_loss: 113.7475 - val_mse: 113.7475\n",
            "Epoch 202/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 105.1353 - mse: 105.1353 - val_loss: 102.1042 - val_mse: 102.1042\n",
            "Epoch 203/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.7395 - mse: 103.7395 - val_loss: 95.4224 - val_mse: 95.4224\n",
            "Epoch 204/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.2385 - mse: 98.2385 - val_loss: 101.3555 - val_mse: 101.3555\n",
            "Epoch 205/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.3953 - mse: 98.3953 - val_loss: 100.3193 - val_mse: 100.3193\n",
            "Epoch 206/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1286 - mse: 98.1286 - val_loss: 96.1697 - val_mse: 96.1697\n",
            "Epoch 207/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 97.1236 - mse: 97.1236 - val_loss: 95.9517 - val_mse: 95.9517\n",
            "Epoch 208/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.4401 - mse: 97.4401 - val_loss: 97.2799 - val_mse: 97.2799\n",
            "Epoch 209/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.5947 - mse: 96.5947 - val_loss: 97.2212 - val_mse: 97.2212\n",
            "Epoch 210/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.5676 - mse: 97.5676 - val_loss: 97.1010 - val_mse: 97.1010\n",
            "Epoch 211/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.6107 - mse: 96.6107 - val_loss: 98.5966 - val_mse: 98.5966\n",
            "Epoch 212/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 97.4462 - mse: 97.4462 - val_loss: 96.4443 - val_mse: 96.4443\n",
            "Epoch 213/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1548 - mse: 98.1548 - val_loss: 98.4837 - val_mse: 98.4837\n",
            "Epoch 214/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.9799 - mse: 97.9799 - val_loss: 95.9392 - val_mse: 95.9392\n",
            "Epoch 215/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.0927 - mse: 96.0927 - val_loss: 95.4905 - val_mse: 95.4905\n",
            "Epoch 216/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.2025 - mse: 96.2025 - val_loss: 95.9205 - val_mse: 95.9205\n",
            "Epoch 217/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.0351 - mse: 96.0351 - val_loss: 99.8135 - val_mse: 99.8135\n",
            "Epoch 218/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.4127 - mse: 99.4127 - val_loss: 94.9846 - val_mse: 94.9846\n",
            "Epoch 219/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.9007 - mse: 100.9007 - val_loss: 100.5068 - val_mse: 100.5068\n",
            "Epoch 220/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.3529 - mse: 98.3529 - val_loss: 96.7638 - val_mse: 96.7638\n",
            "Epoch 221/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0569 - mse: 99.0569 - val_loss: 102.1269 - val_mse: 102.1269\n",
            "Epoch 222/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.7379 - mse: 97.7379 - val_loss: 109.9495 - val_mse: 109.9495\n",
            "Epoch 223/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.1213 - mse: 103.1213 - val_loss: 95.1311 - val_mse: 95.1311\n",
            "Epoch 224/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.9881 - mse: 97.9881 - val_loss: 96.2027 - val_mse: 96.2027\n",
            "Epoch 225/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.6268 - mse: 97.6268 - val_loss: 98.3340 - val_mse: 98.3340\n",
            "Epoch 226/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.7137 - mse: 103.7137 - val_loss: 102.5057 - val_mse: 102.5057\n",
            "Epoch 227/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 101.4768 - mse: 101.4768 - val_loss: 95.1077 - val_mse: 95.1077\n",
            "Epoch 228/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 96.9620 - mse: 96.9620 - val_loss: 94.8505 - val_mse: 94.8505\n",
            "Epoch 229/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 96.1941 - mse: 96.1941 - val_loss: 97.4389 - val_mse: 97.4389\n",
            "Epoch 230/1000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 96.5842 - mse: 96.5842 - val_loss: 95.5987 - val_mse: 95.5987\n",
            "Epoch 231/1000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 97.8065 - mse: 97.8065 - val_loss: 96.1161 - val_mse: 96.1161\n",
            "Epoch 232/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 96.9375 - mse: 96.9375 - val_loss: 95.3810 - val_mse: 95.3810\n",
            "Epoch 233/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 97.5830 - mse: 97.5830 - val_loss: 109.2960 - val_mse: 109.2960\n",
            "Epoch 234/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 101.9560 - mse: 101.9560 - val_loss: 94.8911 - val_mse: 94.8911\n",
            "Epoch 235/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.9181 - mse: 95.9181 - val_loss: 95.6960 - val_mse: 95.6960\n",
            "Epoch 236/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.5926 - mse: 96.5926 - val_loss: 95.1630 - val_mse: 95.1630\n",
            "Epoch 237/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.5975 - mse: 97.5975 - val_loss: 94.6825 - val_mse: 94.6825\n",
            "Epoch 238/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.7165 - mse: 100.7165 - val_loss: 96.4665 - val_mse: 96.4665\n",
            "Epoch 239/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.5327 - mse: 97.5327 - val_loss: 94.8475 - val_mse: 94.8475\n",
            "Epoch 240/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.6953 - mse: 95.6953 - val_loss: 95.4919 - val_mse: 95.4919\n",
            "Epoch 241/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.0711 - mse: 96.0711 - val_loss: 94.5680 - val_mse: 94.5680\n",
            "Epoch 242/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.9609 - mse: 95.9609 - val_loss: 94.6513 - val_mse: 94.6513\n",
            "Epoch 243/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.3000 - mse: 97.3000 - val_loss: 94.8261 - val_mse: 94.8261\n",
            "Epoch 244/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.5124 - mse: 98.5124 - val_loss: 99.6570 - val_mse: 99.6570\n",
            "Epoch 245/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.2848 - mse: 97.2848 - val_loss: 95.8694 - val_mse: 95.8694\n",
            "Epoch 246/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.9289 - mse: 96.9289 - val_loss: 94.6264 - val_mse: 94.6264\n",
            "Epoch 247/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.2596 - mse: 96.2596 - val_loss: 99.4987 - val_mse: 99.4987\n",
            "Epoch 248/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.2178 - mse: 99.2178 - val_loss: 102.3209 - val_mse: 102.3209\n",
            "Epoch 249/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.4874 - mse: 99.4874 - val_loss: 94.9969 - val_mse: 94.9969\n",
            "Epoch 250/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.8431 - mse: 95.8431 - val_loss: 94.4772 - val_mse: 94.4772\n",
            "Epoch 251/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.8065 - mse: 95.8065 - val_loss: 94.4792 - val_mse: 94.4792\n",
            "Epoch 252/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.8186 - mse: 96.8186 - val_loss: 95.0586 - val_mse: 95.0586\n",
            "Epoch 253/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.0809 - mse: 96.0809 - val_loss: 95.2506 - val_mse: 95.2506\n",
            "Epoch 254/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.4508 - mse: 96.4508 - val_loss: 99.8169 - val_mse: 99.8169\n",
            "Epoch 255/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.3167 - mse: 100.3167 - val_loss: 94.5302 - val_mse: 94.5302\n",
            "Epoch 256/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.7003 - mse: 99.7003 - val_loss: 100.8036 - val_mse: 100.8036\n",
            "Epoch 257/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.9811 - mse: 97.9811 - val_loss: 95.0151 - val_mse: 95.0151\n",
            "Epoch 258/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.2657 - mse: 98.2657 - val_loss: 97.6967 - val_mse: 97.6967\n",
            "Epoch 259/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.5893 - mse: 96.5893 - val_loss: 94.6903 - val_mse: 94.6903\n",
            "Epoch 260/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.0183 - mse: 97.0183 - val_loss: 95.1785 - val_mse: 95.1785\n",
            "Epoch 261/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.4077 - mse: 97.4077 - val_loss: 95.9087 - val_mse: 95.9087\n",
            "Epoch 262/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.2081 - mse: 97.2081 - val_loss: 95.6373 - val_mse: 95.6373\n",
            "Epoch 263/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.1948 - mse: 97.1948 - val_loss: 96.0786 - val_mse: 96.0786\n",
            "Epoch 264/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.9376 - mse: 95.9376 - val_loss: 95.3734 - val_mse: 95.3734\n",
            "Epoch 265/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.1691 - mse: 98.1691 - val_loss: 99.2902 - val_mse: 99.2902\n",
            "Epoch 266/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.3420 - mse: 97.3420 - val_loss: 98.1472 - val_mse: 98.1472\n",
            "Epoch 267/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.4141 - mse: 98.4141 - val_loss: 99.7686 - val_mse: 99.7686\n",
            "Epoch 268/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.3688 - mse: 98.3688 - val_loss: 94.2452 - val_mse: 94.2452\n",
            "Epoch 269/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.6945 - mse: 97.6945 - val_loss: 94.2382 - val_mse: 94.2382\n",
            "Epoch 270/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.3852 - mse: 95.3852 - val_loss: 95.2225 - val_mse: 95.2225\n",
            "Epoch 271/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.5895 - mse: 95.5895 - val_loss: 107.8471 - val_mse: 107.8471\n",
            "Epoch 272/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.2970 - mse: 103.2970 - val_loss: 98.0656 - val_mse: 98.0656\n",
            "Epoch 273/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 100.9731 - mse: 100.9731 - val_loss: 94.8666 - val_mse: 94.8666\n",
            "Epoch 274/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.2376 - mse: 96.2376 - val_loss: 94.1324 - val_mse: 94.1324\n",
            "Epoch 275/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.6084 - mse: 95.6084 - val_loss: 96.7192 - val_mse: 96.7192\n",
            "Epoch 276/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.8560 - mse: 95.8560 - val_loss: 94.3916 - val_mse: 94.3916\n",
            "Epoch 277/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.3567 - mse: 95.3567 - val_loss: 95.6259 - val_mse: 95.6259\n",
            "Epoch 278/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.3148 - mse: 96.3148 - val_loss: 97.7297 - val_mse: 97.7297\n",
            "Epoch 279/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.7682 - mse: 95.7682 - val_loss: 95.3902 - val_mse: 95.3902\n",
            "Epoch 280/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.6448 - mse: 95.6448 - val_loss: 95.4269 - val_mse: 95.4269\n",
            "Epoch 281/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.3435 - mse: 98.3435 - val_loss: 95.8696 - val_mse: 95.8696\n",
            "Epoch 282/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.2276 - mse: 95.2276 - val_loss: 94.5045 - val_mse: 94.5045\n",
            "Epoch 283/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.3514 - mse: 95.3514 - val_loss: 94.0365 - val_mse: 94.0365\n",
            "Epoch 284/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.4264 - mse: 96.4264 - val_loss: 94.7723 - val_mse: 94.7723\n",
            "Epoch 285/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.2470 - mse: 96.2470 - val_loss: 93.9545 - val_mse: 93.9545\n",
            "Epoch 286/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6837 - mse: 94.6837 - val_loss: 99.2798 - val_mse: 99.2798\n",
            "Epoch 287/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.8770 - mse: 95.8770 - val_loss: 94.4584 - val_mse: 94.4584\n",
            "Epoch 288/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.0727 - mse: 96.0727 - val_loss: 98.8931 - val_mse: 98.8931\n",
            "Epoch 289/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.2086 - mse: 98.2086 - val_loss: 95.4832 - val_mse: 95.4832\n",
            "Epoch 290/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.1227 - mse: 95.1227 - val_loss: 102.0912 - val_mse: 102.0912\n",
            "Epoch 291/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.9308 - mse: 97.9308 - val_loss: 94.1191 - val_mse: 94.1191\n",
            "Epoch 292/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.5938 - mse: 95.5938 - val_loss: 95.3431 - val_mse: 95.3431\n",
            "Epoch 293/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.2888 - mse: 95.2888 - val_loss: 95.6844 - val_mse: 95.6844\n",
            "Epoch 294/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.0096 - mse: 100.0096 - val_loss: 122.4198 - val_mse: 122.4198\n",
            "Epoch 295/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 107.6520 - mse: 107.6520 - val_loss: 135.5097 - val_mse: 135.5097\n",
            "Epoch 296/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 117.8648 - mse: 117.8648 - val_loss: 121.7293 - val_mse: 121.7293\n",
            "Epoch 297/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 109.8404 - mse: 109.8404 - val_loss: 96.1966 - val_mse: 96.1966\n",
            "Epoch 298/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.9114 - mse: 101.9114 - val_loss: 97.2728 - val_mse: 97.2728\n",
            "Epoch 299/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.5378 - mse: 99.5378 - val_loss: 93.9103 - val_mse: 93.9103\n",
            "Epoch 300/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.1287 - mse: 97.1287 - val_loss: 94.9515 - val_mse: 94.9515\n",
            "Epoch 301/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 96.7513 - mse: 96.7513 - val_loss: 93.9248 - val_mse: 93.9248\n",
            "Epoch 302/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.8598 - mse: 94.8598 - val_loss: 101.4819 - val_mse: 101.4819\n",
            "Epoch 303/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.5304 - mse: 97.5304 - val_loss: 102.8049 - val_mse: 102.8049\n",
            "Epoch 304/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.0411 - mse: 98.0411 - val_loss: 97.8052 - val_mse: 97.8052\n",
            "Epoch 305/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.7168 - mse: 95.7168 - val_loss: 93.7546 - val_mse: 93.7546\n",
            "Epoch 306/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.2628 - mse: 95.2628 - val_loss: 94.3365 - val_mse: 94.3365\n",
            "Epoch 307/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.2566 - mse: 98.2566 - val_loss: 94.0241 - val_mse: 94.0241\n",
            "Epoch 308/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.3257 - mse: 100.3257 - val_loss: 95.8356 - val_mse: 95.8356\n",
            "Epoch 309/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 105.6541 - mse: 105.6541 - val_loss: 96.7650 - val_mse: 96.7650\n",
            "Epoch 310/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 107.6632 - mse: 107.6632 - val_loss: 93.8188 - val_mse: 93.8188\n",
            "Epoch 311/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.1489 - mse: 103.1489 - val_loss: 94.2601 - val_mse: 94.2601\n",
            "Epoch 312/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.3784 - mse: 102.3784 - val_loss: 99.1073 - val_mse: 99.1073\n",
            "Epoch 313/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.2758 - mse: 100.2758 - val_loss: 120.4385 - val_mse: 120.4385\n",
            "Epoch 314/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.8066 - mse: 104.8066 - val_loss: 97.2741 - val_mse: 97.2741\n",
            "Epoch 315/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.6834 - mse: 95.6834 - val_loss: 98.2135 - val_mse: 98.2135\n",
            "Epoch 316/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 94.9081 - mse: 94.9081 - val_loss: 95.8209 - val_mse: 95.8209\n",
            "Epoch 317/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.2888 - mse: 96.2888 - val_loss: 95.7833 - val_mse: 95.7833\n",
            "Epoch 318/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.3342 - mse: 97.3342 - val_loss: 95.3887 - val_mse: 95.3887\n",
            "Epoch 319/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.1275 - mse: 96.1275 - val_loss: 97.0915 - val_mse: 97.0915\n",
            "Epoch 320/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.0047 - mse: 97.0047 - val_loss: 105.0233 - val_mse: 105.0233\n",
            "Epoch 321/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.2616 - mse: 101.2616 - val_loss: 93.8090 - val_mse: 93.8090\n",
            "Epoch 322/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.8185 - mse: 95.8185 - val_loss: 93.5590 - val_mse: 93.5590\n",
            "Epoch 323/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.8681 - mse: 93.8681 - val_loss: 93.7661 - val_mse: 93.7661\n",
            "Epoch 324/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6542 - mse: 94.6542 - val_loss: 94.3832 - val_mse: 94.3832\n",
            "Epoch 325/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6102 - mse: 94.6102 - val_loss: 97.4332 - val_mse: 97.4332\n",
            "Epoch 326/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 95.7131 - mse: 95.7131 - val_loss: 94.8173 - val_mse: 94.8173\n",
            "Epoch 327/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.3123 - mse: 95.3123 - val_loss: 96.0756 - val_mse: 96.0756\n",
            "Epoch 328/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 95.0880 - mse: 95.0880 - val_loss: 93.6068 - val_mse: 93.6068\n",
            "Epoch 329/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 94.4464 - mse: 94.4464 - val_loss: 93.6172 - val_mse: 93.6172\n",
            "Epoch 330/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 98.8181 - mse: 98.8181 - val_loss: 113.0703 - val_mse: 113.0703\n",
            "Epoch 331/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 101.9456 - mse: 101.9456 - val_loss: 127.0055 - val_mse: 127.0055\n",
            "Epoch 332/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 107.1863 - mse: 107.1863 - val_loss: 101.8793 - val_mse: 101.8793\n",
            "Epoch 333/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.6918 - mse: 99.6918 - val_loss: 93.9093 - val_mse: 93.9093\n",
            "Epoch 334/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.6857 - mse: 94.6857 - val_loss: 95.4287 - val_mse: 95.4287\n",
            "Epoch 335/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.1194 - mse: 97.1194 - val_loss: 103.0133 - val_mse: 103.0133\n",
            "Epoch 336/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.0027 - mse: 98.0027 - val_loss: 100.3201 - val_mse: 100.3201\n",
            "Epoch 337/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.7000 - mse: 97.7000 - val_loss: 93.7649 - val_mse: 93.7649\n",
            "Epoch 338/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.3898 - mse: 94.3898 - val_loss: 94.2106 - val_mse: 94.2106\n",
            "Epoch 339/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.7062 - mse: 93.7062 - val_loss: 103.2160 - val_mse: 103.2160\n",
            "Epoch 340/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.0143 - mse: 99.0143 - val_loss: 96.2395 - val_mse: 96.2395\n",
            "Epoch 341/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.7885 - mse: 94.7885 - val_loss: 100.8815 - val_mse: 100.8815\n",
            "Epoch 342/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.4061 - mse: 99.4061 - val_loss: 93.2813 - val_mse: 93.2813\n",
            "Epoch 343/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.4494 - mse: 93.4494 - val_loss: 93.3219 - val_mse: 93.3219\n",
            "Epoch 344/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.9588 - mse: 93.9588 - val_loss: 93.3625 - val_mse: 93.3625\n",
            "Epoch 345/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.5220 - mse: 93.5220 - val_loss: 92.8629 - val_mse: 92.8629\n",
            "Epoch 346/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.0521 - mse: 94.0521 - val_loss: 99.3463 - val_mse: 99.3463\n",
            "Epoch 347/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.9839 - mse: 95.9839 - val_loss: 94.9747 - val_mse: 94.9747\n",
            "Epoch 348/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.6546 - mse: 93.6546 - val_loss: 105.9001 - val_mse: 105.9001\n",
            "Epoch 349/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.9785 - mse: 103.9785 - val_loss: 93.5765 - val_mse: 93.5765\n",
            "Epoch 350/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.4461 - mse: 97.4461 - val_loss: 93.3783 - val_mse: 93.3783\n",
            "Epoch 351/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.1425 - mse: 97.1425 - val_loss: 93.2002 - val_mse: 93.2002\n",
            "Epoch 352/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.1198 - mse: 96.1198 - val_loss: 94.8430 - val_mse: 94.8430\n",
            "Epoch 353/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.6086 - mse: 96.6086 - val_loss: 93.7377 - val_mse: 93.7377\n",
            "Epoch 354/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.4466 - mse: 95.4466 - val_loss: 93.1555 - val_mse: 93.1555\n",
            "Epoch 355/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.1831 - mse: 93.1831 - val_loss: 94.0989 - val_mse: 94.0989\n",
            "Epoch 356/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.0916 - mse: 93.0916 - val_loss: 92.9075 - val_mse: 92.9075\n",
            "Epoch 357/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 94.8002 - mse: 94.8002 - val_loss: 94.8058 - val_mse: 94.8058\n",
            "Epoch 358/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 94.3605 - mse: 94.3605 - val_loss: 92.6331 - val_mse: 92.6331\n",
            "Epoch 359/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.0088 - mse: 94.0088 - val_loss: 94.5068 - val_mse: 94.5068\n",
            "Epoch 360/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.9976 - mse: 96.9976 - val_loss: 93.0653 - val_mse: 93.0653\n",
            "Epoch 361/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.5436 - mse: 97.5436 - val_loss: 108.3493 - val_mse: 108.3493\n",
            "Epoch 362/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 102.3521 - mse: 102.3521 - val_loss: 99.1392 - val_mse: 99.1392\n",
            "Epoch 363/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.0686 - mse: 98.0686 - val_loss: 94.4376 - val_mse: 94.4376\n",
            "Epoch 364/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.8005 - mse: 94.8005 - val_loss: 92.5874 - val_mse: 92.5874\n",
            "Epoch 365/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.2111 - mse: 93.2111 - val_loss: 94.4391 - val_mse: 94.4391\n",
            "Epoch 366/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.3673 - mse: 96.3673 - val_loss: 97.3400 - val_mse: 97.3400\n",
            "Epoch 367/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 102.3322 - mse: 102.3322 - val_loss: 118.9326 - val_mse: 118.9326\n",
            "Epoch 368/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.2422 - mse: 102.2422 - val_loss: 99.8928 - val_mse: 99.8928\n",
            "Epoch 369/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 99.0878 - mse: 99.0878 - val_loss: 95.0969 - val_mse: 95.0969\n",
            "Epoch 370/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 102.1791 - mse: 102.1791 - val_loss: 97.7328 - val_mse: 97.7328\n",
            "Epoch 371/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 93.9753 - mse: 93.9753 - val_loss: 93.2017 - val_mse: 93.2017\n",
            "Epoch 372/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 93.7216 - mse: 93.7216 - val_loss: 96.8895 - val_mse: 96.8895\n",
            "Epoch 373/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.6082 - mse: 97.6082 - val_loss: 127.9764 - val_mse: 127.9764\n",
            "Epoch 374/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 106.0711 - mse: 106.0711 - val_loss: 92.5229 - val_mse: 92.5229\n",
            "Epoch 375/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.0556 - mse: 94.0556 - val_loss: 95.2375 - val_mse: 95.2375\n",
            "Epoch 376/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.2953 - mse: 93.2953 - val_loss: 97.7033 - val_mse: 97.7033\n",
            "Epoch 377/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.6909 - mse: 99.6909 - val_loss: 110.0295 - val_mse: 110.0295\n",
            "Epoch 378/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.4561 - mse: 101.4561 - val_loss: 107.8203 - val_mse: 107.8203\n",
            "Epoch 379/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.1171 - mse: 103.1171 - val_loss: 116.6079 - val_mse: 116.6079\n",
            "Epoch 380/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.1285 - mse: 100.1285 - val_loss: 93.4937 - val_mse: 93.4937\n",
            "Epoch 381/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.3349 - mse: 92.3349 - val_loss: 94.6578 - val_mse: 94.6578\n",
            "Epoch 382/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.3102 - mse: 93.3102 - val_loss: 93.6731 - val_mse: 93.6731\n",
            "Epoch 383/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6414 - mse: 94.6414 - val_loss: 92.4135 - val_mse: 92.4135\n",
            "Epoch 384/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.7485 - mse: 92.7485 - val_loss: 92.0479 - val_mse: 92.0479\n",
            "Epoch 385/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.7235 - mse: 92.7235 - val_loss: 93.4100 - val_mse: 93.4100\n",
            "Epoch 386/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.2765 - mse: 94.2765 - val_loss: 92.9404 - val_mse: 92.9404\n",
            "Epoch 387/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6440 - mse: 94.6440 - val_loss: 92.1619 - val_mse: 92.1619\n",
            "Epoch 388/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.5814 - mse: 92.5814 - val_loss: 92.7419 - val_mse: 92.7419\n",
            "Epoch 389/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.6564 - mse: 92.6564 - val_loss: 98.6005 - val_mse: 98.6005\n",
            "Epoch 390/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.1594 - mse: 95.1594 - val_loss: 92.0757 - val_mse: 92.0757\n",
            "Epoch 391/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.2285 - mse: 92.2285 - val_loss: 95.6254 - val_mse: 95.6254\n",
            "Epoch 392/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 93.8530 - mse: 93.8530 - val_loss: 94.9679 - val_mse: 94.9679\n",
            "Epoch 393/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.4221 - mse: 95.4221 - val_loss: 91.6929 - val_mse: 91.6929\n",
            "Epoch 394/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.1713 - mse: 93.1713 - val_loss: 94.5322 - val_mse: 94.5322\n",
            "Epoch 395/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.6355 - mse: 91.6355 - val_loss: 97.5963 - val_mse: 97.5963\n",
            "Epoch 396/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.0053 - mse: 99.0053 - val_loss: 91.5565 - val_mse: 91.5565\n",
            "Epoch 397/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.6118 - mse: 91.6118 - val_loss: 93.8384 - val_mse: 93.8384\n",
            "Epoch 398/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.6123 - mse: 92.6123 - val_loss: 99.6080 - val_mse: 99.6080\n",
            "Epoch 399/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 98.1211 - mse: 98.1211 - val_loss: 120.1452 - val_mse: 120.1452\n",
            "Epoch 400/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 102.1342 - mse: 102.1342 - val_loss: 93.2822 - val_mse: 93.2822\n",
            "Epoch 401/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.2568 - mse: 95.2568 - val_loss: 93.9061 - val_mse: 93.9061\n",
            "Epoch 402/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.6786 - mse: 97.6786 - val_loss: 97.2744 - val_mse: 97.2744\n",
            "Epoch 403/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.7829 - mse: 93.7829 - val_loss: 95.8151 - val_mse: 95.8151\n",
            "Epoch 404/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.4381 - mse: 99.4381 - val_loss: 92.8854 - val_mse: 92.8854\n",
            "Epoch 405/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 97.6962 - mse: 97.6962 - val_loss: 94.6155 - val_mse: 94.6155\n",
            "Epoch 406/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.1335 - mse: 91.1335 - val_loss: 92.5657 - val_mse: 92.5657\n",
            "Epoch 407/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.1843 - mse: 91.1843 - val_loss: 97.5930 - val_mse: 97.5930\n",
            "Epoch 408/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.4851 - mse: 91.4851 - val_loss: 94.4242 - val_mse: 94.4242\n",
            "Epoch 409/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.7358 - mse: 92.7358 - val_loss: 91.1905 - val_mse: 91.1905\n",
            "Epoch 410/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.6110 - mse: 93.6110 - val_loss: 91.0679 - val_mse: 91.0679\n",
            "Epoch 411/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.4990 - mse: 91.4990 - val_loss: 93.4001 - val_mse: 93.4001\n",
            "Epoch 412/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.5900 - mse: 91.5900 - val_loss: 97.5914 - val_mse: 97.5914\n",
            "Epoch 413/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.3246 - mse: 97.3246 - val_loss: 92.3030 - val_mse: 92.3030\n",
            "Epoch 414/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.6415 - mse: 100.6415 - val_loss: 91.3141 - val_mse: 91.3141\n",
            "Epoch 415/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 90.4654 - mse: 90.4654 - val_loss: 97.3856 - val_mse: 97.3856\n",
            "Epoch 416/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.1307 - mse: 94.1307 - val_loss: 92.2796 - val_mse: 92.2796\n",
            "Epoch 417/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 104.5360 - mse: 104.5360 - val_loss: 96.0678 - val_mse: 96.0678\n",
            "Epoch 418/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.6106 - mse: 100.6106 - val_loss: 91.2012 - val_mse: 91.2012\n",
            "Epoch 419/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.5834 - mse: 90.5834 - val_loss: 107.8233 - val_mse: 107.8233\n",
            "Epoch 420/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 101.0734 - mse: 101.0734 - val_loss: 95.3887 - val_mse: 95.3887\n",
            "Epoch 421/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.7816 - mse: 103.7816 - val_loss: 92.4052 - val_mse: 92.4052\n",
            "Epoch 422/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.4000 - mse: 91.4000 - val_loss: 91.5689 - val_mse: 91.5689\n",
            "Epoch 423/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.0502 - mse: 90.0502 - val_loss: 93.1760 - val_mse: 93.1760\n",
            "Epoch 424/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.9848 - mse: 89.9848 - val_loss: 90.9879 - val_mse: 90.9879\n",
            "Epoch 425/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.5638 - mse: 89.5638 - val_loss: 91.1489 - val_mse: 91.1489\n",
            "Epoch 426/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.7544 - mse: 92.7544 - val_loss: 95.7460 - val_mse: 95.7460\n",
            "Epoch 427/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.0820 - mse: 91.0820 - val_loss: 97.5120 - val_mse: 97.5120\n",
            "Epoch 428/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.2102 - mse: 95.2102 - val_loss: 98.1822 - val_mse: 98.1822\n",
            "Epoch 429/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.2114 - mse: 102.2114 - val_loss: 90.8095 - val_mse: 90.8095\n",
            "Epoch 430/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.3784 - mse: 97.3784 - val_loss: 95.5807 - val_mse: 95.5807\n",
            "Epoch 431/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.1789 - mse: 93.1789 - val_loss: 97.1128 - val_mse: 97.1128\n",
            "Epoch 432/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.0470 - mse: 92.0470 - val_loss: 90.3341 - val_mse: 90.3341\n",
            "Epoch 433/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.6852 - mse: 98.6852 - val_loss: 91.3051 - val_mse: 91.3051\n",
            "Epoch 434/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 108.0762 - mse: 108.0762 - val_loss: 103.8985 - val_mse: 103.8985\n",
            "Epoch 435/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.4695 - mse: 100.4695 - val_loss: 93.0463 - val_mse: 93.0463\n",
            "Epoch 436/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.5434 - mse: 89.5434 - val_loss: 94.2791 - val_mse: 94.2791\n",
            "Epoch 437/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.4247 - mse: 91.4247 - val_loss: 90.4175 - val_mse: 90.4175\n",
            "Epoch 438/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.7187 - mse: 89.7187 - val_loss: 95.6546 - val_mse: 95.6546\n",
            "Epoch 439/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.2613 - mse: 93.2613 - val_loss: 90.7965 - val_mse: 90.7965\n",
            "Epoch 440/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.7009 - mse: 91.7009 - val_loss: 90.6637 - val_mse: 90.6637\n",
            "Epoch 441/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.4745 - mse: 91.4745 - val_loss: 91.8244 - val_mse: 91.8244\n",
            "Epoch 442/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.6700 - mse: 92.6700 - val_loss: 117.1335 - val_mse: 117.1335\n",
            "Epoch 443/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.0035 - mse: 97.0035 - val_loss: 93.5827 - val_mse: 93.5827\n",
            "Epoch 444/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.2395 - mse: 95.2395 - val_loss: 90.6126 - val_mse: 90.6126\n",
            "Epoch 445/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.6328 - mse: 89.6328 - val_loss: 95.0640 - val_mse: 95.0640\n",
            "Epoch 446/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.1771 - mse: 91.1771 - val_loss: 91.0753 - val_mse: 91.0753\n",
            "Epoch 447/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.5823 - mse: 91.5823 - val_loss: 94.4956 - val_mse: 94.4956\n",
            "Epoch 448/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 91.8226 - mse: 91.8226 - val_loss: 90.3306 - val_mse: 90.3306\n",
            "Epoch 449/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.1073 - mse: 91.1073 - val_loss: 90.8784 - val_mse: 90.8784\n",
            "Epoch 450/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.6721 - mse: 91.6721 - val_loss: 90.1930 - val_mse: 90.1930\n",
            "Epoch 451/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.6215 - mse: 88.6215 - val_loss: 107.8700 - val_mse: 107.8700\n",
            "Epoch 452/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.1117 - mse: 94.1117 - val_loss: 92.5062 - val_mse: 92.5062\n",
            "Epoch 453/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.3377 - mse: 90.3377 - val_loss: 106.4246 - val_mse: 106.4246\n",
            "Epoch 454/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.2322 - mse: 100.2322 - val_loss: 106.8449 - val_mse: 106.8449\n",
            "Epoch 455/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.8918 - mse: 96.8918 - val_loss: 101.2984 - val_mse: 101.2984\n",
            "Epoch 456/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.1156 - mse: 99.1156 - val_loss: 100.9770 - val_mse: 100.9770\n",
            "Epoch 457/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.2048 - mse: 94.2048 - val_loss: 89.8133 - val_mse: 89.8133\n",
            "Epoch 458/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 108.1001 - mse: 108.1001 - val_loss: 92.0900 - val_mse: 92.0900\n",
            "Epoch 459/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 117.9834 - mse: 117.9834 - val_loss: 97.7120 - val_mse: 97.7120\n",
            "Epoch 460/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.9972 - mse: 92.9972 - val_loss: 89.6339 - val_mse: 89.6339\n",
            "Epoch 461/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.9569 - mse: 87.9569 - val_loss: 90.0714 - val_mse: 90.0714\n",
            "Epoch 462/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.4264 - mse: 88.4264 - val_loss: 91.3118 - val_mse: 91.3118\n",
            "Epoch 463/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.5397 - mse: 87.5397 - val_loss: 89.7980 - val_mse: 89.7980\n",
            "Epoch 464/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 88.3147 - mse: 88.3147 - val_loss: 89.5583 - val_mse: 89.5583\n",
            "Epoch 465/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.8727 - mse: 88.8727 - val_loss: 94.5234 - val_mse: 94.5234\n",
            "Epoch 466/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.7727 - mse: 88.7727 - val_loss: 90.0231 - val_mse: 90.0231\n",
            "Epoch 467/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.4493 - mse: 94.4493 - val_loss: 89.4553 - val_mse: 89.4553\n",
            "Epoch 468/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.1290 - mse: 88.1290 - val_loss: 92.5506 - val_mse: 92.5506\n",
            "Epoch 469/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.9165 - mse: 88.9165 - val_loss: 90.0750 - val_mse: 90.0750\n",
            "Epoch 470/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.6947 - mse: 94.6947 - val_loss: 89.5930 - val_mse: 89.5930\n",
            "Epoch 471/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 100.1330 - mse: 100.1330 - val_loss: 107.4739 - val_mse: 107.4739\n",
            "Epoch 472/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.8691 - mse: 103.8691 - val_loss: 90.1044 - val_mse: 90.1044\n",
            "Epoch 473/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.9311 - mse: 87.9311 - val_loss: 112.3783 - val_mse: 112.3783\n",
            "Epoch 474/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 112.6424 - mse: 112.6424 - val_loss: 102.2351 - val_mse: 102.2351\n",
            "Epoch 475/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.1703 - mse: 95.1703 - val_loss: 148.4342 - val_mse: 148.4342\n",
            "Epoch 476/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 109.5999 - mse: 109.5999 - val_loss: 113.8622 - val_mse: 113.8622\n",
            "Epoch 477/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.3307 - mse: 98.3307 - val_loss: 97.1489 - val_mse: 97.1489\n",
            "Epoch 478/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.0626 - mse: 104.0626 - val_loss: 89.8147 - val_mse: 89.8147\n",
            "Epoch 479/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.5405 - mse: 93.5405 - val_loss: 99.8796 - val_mse: 99.8796\n",
            "Epoch 480/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.5480 - mse: 90.5480 - val_loss: 90.0187 - val_mse: 90.0187\n",
            "Epoch 481/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.5078 - mse: 88.5078 - val_loss: 92.8462 - val_mse: 92.8462\n",
            "Epoch 482/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.6112 - mse: 95.6112 - val_loss: 89.5070 - val_mse: 89.5070\n",
            "Epoch 483/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.6967 - mse: 86.6967 - val_loss: 91.7899 - val_mse: 91.7899\n",
            "Epoch 484/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.9673 - mse: 87.9673 - val_loss: 104.8834 - val_mse: 104.8834\n",
            "Epoch 485/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.2684 - mse: 97.2684 - val_loss: 95.5362 - val_mse: 95.5362\n",
            "Epoch 486/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 91.1990 - mse: 91.1990 - val_loss: 99.3690 - val_mse: 99.3690\n",
            "Epoch 487/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.3790 - mse: 90.3790 - val_loss: 90.0485 - val_mse: 90.0485\n",
            "Epoch 488/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.7202 - mse: 94.7202 - val_loss: 93.5835 - val_mse: 93.5835\n",
            "Epoch 489/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 97.5763 - mse: 97.5763 - val_loss: 89.3662 - val_mse: 89.3662\n",
            "Epoch 490/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.3513 - mse: 92.3513 - val_loss: 106.3861 - val_mse: 106.3861\n",
            "Epoch 491/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.0385 - mse: 95.0385 - val_loss: 97.9918 - val_mse: 97.9918\n",
            "Epoch 492/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 122.0874 - mse: 122.0874 - val_loss: 136.7900 - val_mse: 136.7900\n",
            "Epoch 493/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 115.4619 - mse: 115.4619 - val_loss: 163.5878 - val_mse: 163.5878\n",
            "Epoch 494/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 117.3113 - mse: 117.3113 - val_loss: 118.4575 - val_mse: 118.4575\n",
            "Epoch 495/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 110.5917 - mse: 110.5917 - val_loss: 89.0830 - val_mse: 89.0830\n",
            "Epoch 496/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 105.8792 - mse: 105.8792 - val_loss: 112.2409 - val_mse: 112.2409\n",
            "Epoch 497/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 119.8657 - mse: 119.8657 - val_loss: 107.6897 - val_mse: 107.6897\n",
            "Epoch 498/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.7931 - mse: 92.7931 - val_loss: 89.9796 - val_mse: 89.9796\n",
            "Epoch 499/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.0616 - mse: 87.0616 - val_loss: 104.7546 - val_mse: 104.7546\n",
            "Epoch 500/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.8527 - mse: 94.8527 - val_loss: 90.8256 - val_mse: 90.8256\n",
            "Epoch 501/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.1385 - mse: 89.1385 - val_loss: 93.9037 - val_mse: 93.9037\n",
            "Epoch 502/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.3485 - mse: 100.3485 - val_loss: 90.0563 - val_mse: 90.0563\n",
            "Epoch 503/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 86.8930 - mse: 86.8930 - val_loss: 89.4230 - val_mse: 89.4230\n",
            "Epoch 504/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.4352 - mse: 90.4352 - val_loss: 90.6546 - val_mse: 90.6546\n",
            "Epoch 505/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 91.4210 - mse: 91.4210 - val_loss: 89.1190 - val_mse: 89.1190\n",
            "Epoch 506/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.5620 - mse: 87.5620 - val_loss: 88.8221 - val_mse: 88.8221\n",
            "Epoch 507/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.3773 - mse: 88.3773 - val_loss: 89.0207 - val_mse: 89.0207\n",
            "Epoch 508/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.2673 - mse: 88.2673 - val_loss: 91.8167 - val_mse: 91.8167\n",
            "Epoch 509/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.7459 - mse: 88.7459 - val_loss: 92.1363 - val_mse: 92.1363\n",
            "Epoch 510/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.4457 - mse: 96.4457 - val_loss: 106.3171 - val_mse: 106.3171\n",
            "Epoch 511/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 98.9132 - mse: 98.9132 - val_loss: 121.1887 - val_mse: 121.1887\n",
            "Epoch 512/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.6868 - mse: 95.6868 - val_loss: 89.0805 - val_mse: 89.0805\n",
            "Epoch 513/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.1891 - mse: 87.1891 - val_loss: 95.6598 - val_mse: 95.6598\n",
            "Epoch 514/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.0453 - mse: 93.0453 - val_loss: 123.2177 - val_mse: 123.2177\n",
            "Epoch 515/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 107.5136 - mse: 107.5136 - val_loss: 134.6609 - val_mse: 134.6609\n",
            "Epoch 516/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 117.6829 - mse: 117.6829 - val_loss: 114.0105 - val_mse: 114.0105\n",
            "Epoch 517/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 109.1321 - mse: 109.1321 - val_loss: 98.5393 - val_mse: 98.5393\n",
            "Epoch 518/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 120.3104 - mse: 120.3104 - val_loss: 108.5005 - val_mse: 108.5005\n",
            "Epoch 519/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 106.1951 - mse: 106.1951 - val_loss: 112.5360 - val_mse: 112.5360\n",
            "Epoch 520/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.4276 - mse: 93.4276 - val_loss: 92.8724 - val_mse: 92.8724\n",
            "Epoch 521/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.7247 - mse: 87.7247 - val_loss: 92.8957 - val_mse: 92.8957\n",
            "Epoch 522/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 90.1206 - mse: 90.1206 - val_loss: 109.5516 - val_mse: 109.5516\n",
            "Epoch 523/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.6197 - mse: 94.6197 - val_loss: 90.9394 - val_mse: 90.9394\n",
            "Epoch 524/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.3595 - mse: 88.3595 - val_loss: 89.0721 - val_mse: 89.0721\n",
            "Epoch 525/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.6112 - mse: 89.6112 - val_loss: 94.8946 - val_mse: 94.8946\n",
            "Epoch 526/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.6840 - mse: 87.6840 - val_loss: 88.5555 - val_mse: 88.5555\n",
            "Epoch 527/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 87.3554 - mse: 87.3554 - val_loss: 89.8206 - val_mse: 89.8206\n",
            "Epoch 528/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 92.6664 - mse: 92.6664 - val_loss: 93.6594 - val_mse: 93.6594\n",
            "Epoch 529/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.7915 - mse: 88.7915 - val_loss: 92.1996 - val_mse: 92.1996\n",
            "Epoch 530/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.8150 - mse: 91.8150 - val_loss: 90.7235 - val_mse: 90.7235\n",
            "Epoch 531/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.3043 - mse: 92.3043 - val_loss: 89.1380 - val_mse: 89.1380\n",
            "Epoch 532/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.0288 - mse: 88.0288 - val_loss: 90.2000 - val_mse: 90.2000\n",
            "Epoch 533/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.4618 - mse: 88.4618 - val_loss: 89.3845 - val_mse: 89.3845\n",
            "Epoch 534/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.7199 - mse: 87.7199 - val_loss: 93.4352 - val_mse: 93.4352\n",
            "Epoch 535/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 87.4883 - mse: 87.4883 - val_loss: 89.9012 - val_mse: 89.9012\n",
            "Epoch 536/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.4146 - mse: 89.4146 - val_loss: 91.7626 - val_mse: 91.7626\n",
            "Epoch 537/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.3826 - mse: 89.3826 - val_loss: 90.5973 - val_mse: 90.5973\n",
            "Epoch 538/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 88.5898 - mse: 88.5898 - val_loss: 90.0779 - val_mse: 90.0779\n",
            "Epoch 539/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.7093 - mse: 85.7093 - val_loss: 91.6755 - val_mse: 91.6755\n",
            "Epoch 540/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.4162 - mse: 86.4162 - val_loss: 101.9992 - val_mse: 101.9992\n",
            "Epoch 541/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 98.6353 - mse: 98.6353 - val_loss: 119.6896 - val_mse: 119.6896\n",
            "Epoch 542/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.3283 - mse: 97.3283 - val_loss: 88.3630 - val_mse: 88.3630\n",
            "Epoch 543/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 110.2859 - mse: 110.2859 - val_loss: 90.4263 - val_mse: 90.4263\n",
            "Epoch 544/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.3659 - mse: 104.3659 - val_loss: 104.5993 - val_mse: 104.5993\n",
            "Epoch 545/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 107.3302 - mse: 107.3302 - val_loss: 120.3906 - val_mse: 120.3906\n",
            "Epoch 546/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 98.9913 - mse: 98.9913 - val_loss: 114.3070 - val_mse: 114.3070\n",
            "Epoch 547/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.5251 - mse: 102.5251 - val_loss: 90.9631 - val_mse: 90.9631\n",
            "Epoch 548/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.8889 - mse: 92.8889 - val_loss: 93.8745 - val_mse: 93.8745\n",
            "Epoch 549/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.0001 - mse: 89.0001 - val_loss: 93.0708 - val_mse: 93.0708\n",
            "Epoch 550/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.7926 - mse: 86.7926 - val_loss: 91.2195 - val_mse: 91.2195\n",
            "Epoch 551/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.2870 - mse: 85.2870 - val_loss: 90.9647 - val_mse: 90.9647\n",
            "Epoch 552/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.6431 - mse: 88.6431 - val_loss: 96.1337 - val_mse: 96.1337\n",
            "Epoch 553/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.9451 - mse: 97.9451 - val_loss: 88.3074 - val_mse: 88.3074\n",
            "Epoch 554/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.3144 - mse: 91.3144 - val_loss: 88.2811 - val_mse: 88.2811\n",
            "Epoch 555/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.5076 - mse: 86.5076 - val_loss: 89.1169 - val_mse: 89.1169\n",
            "Epoch 556/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.8417 - mse: 84.8417 - val_loss: 92.0620 - val_mse: 92.0620\n",
            "Epoch 557/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.7033 - mse: 95.7033 - val_loss: 118.4630 - val_mse: 118.4630\n",
            "Epoch 558/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 108.5688 - mse: 108.5688 - val_loss: 106.8520 - val_mse: 106.8520\n",
            "Epoch 559/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.7300 - mse: 92.7300 - val_loss: 88.8547 - val_mse: 88.8547\n",
            "Epoch 560/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.1143 - mse: 88.1143 - val_loss: 96.8722 - val_mse: 96.8722\n",
            "Epoch 561/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.5323 - mse: 97.5323 - val_loss: 118.7955 - val_mse: 118.7955\n",
            "Epoch 562/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.7632 - mse: 94.7632 - val_loss: 93.5956 - val_mse: 93.5956\n",
            "Epoch 563/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.0231 - mse: 89.0231 - val_loss: 92.0848 - val_mse: 92.0848\n",
            "Epoch 564/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.7116 - mse: 91.7116 - val_loss: 95.2251 - val_mse: 95.2251\n",
            "Epoch 565/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.0707 - mse: 96.0707 - val_loss: 91.2023 - val_mse: 91.2023\n",
            "Epoch 566/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.4706 - mse: 85.4706 - val_loss: 89.2549 - val_mse: 89.2549\n",
            "Epoch 567/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.5615 - mse: 85.5615 - val_loss: 89.8769 - val_mse: 89.8769\n",
            "Epoch 568/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.6692 - mse: 85.6692 - val_loss: 89.6408 - val_mse: 89.6408\n",
            "Epoch 569/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.4923 - mse: 89.4923 - val_loss: 89.0371 - val_mse: 89.0371\n",
            "Epoch 570/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2611 - mse: 85.2611 - val_loss: 88.8692 - val_mse: 88.8692\n",
            "Epoch 571/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.6130 - mse: 93.6130 - val_loss: 88.2202 - val_mse: 88.2202\n",
            "Epoch 572/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.0406 - mse: 92.0406 - val_loss: 96.0405 - val_mse: 96.0405\n",
            "Epoch 573/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.8979 - mse: 89.8979 - val_loss: 92.5315 - val_mse: 92.5315\n",
            "Epoch 574/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.9632 - mse: 100.9632 - val_loss: 129.2336 - val_mse: 129.2336\n",
            "Epoch 575/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.4038 - mse: 102.4038 - val_loss: 126.9047 - val_mse: 126.9047\n",
            "Epoch 576/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.0987 - mse: 101.0987 - val_loss: 96.8056 - val_mse: 96.8056\n",
            "Epoch 577/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 93.8758 - mse: 93.8758 - val_loss: 88.1111 - val_mse: 88.1111\n",
            "Epoch 578/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.4757 - mse: 90.4757 - val_loss: 107.3014 - val_mse: 107.3014\n",
            "Epoch 579/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 102.8821 - mse: 102.8821 - val_loss: 90.6528 - val_mse: 90.6528\n",
            "Epoch 580/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.3522 - mse: 87.3522 - val_loss: 92.7208 - val_mse: 92.7208\n",
            "Epoch 581/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.2534 - mse: 92.2534 - val_loss: 93.5283 - val_mse: 93.5283\n",
            "Epoch 582/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.2655 - mse: 87.2655 - val_loss: 88.2604 - val_mse: 88.2604\n",
            "Epoch 583/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.1839 - mse: 87.1839 - val_loss: 88.5447 - val_mse: 88.5447\n",
            "Epoch 584/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.4749 - mse: 85.4749 - val_loss: 88.5368 - val_mse: 88.5368\n",
            "Epoch 585/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97.2819 - mse: 97.2819 - val_loss: 88.3391 - val_mse: 88.3391\n",
            "Epoch 586/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.5773 - mse: 91.5773 - val_loss: 89.4134 - val_mse: 89.4134\n",
            "Epoch 587/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.1269 - mse: 86.1269 - val_loss: 98.5940 - val_mse: 98.5940\n",
            "Epoch 588/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 91.8307 - mse: 91.8307 - val_loss: 92.6899 - val_mse: 92.6899\n",
            "Epoch 589/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.1182 - mse: 89.1182 - val_loss: 96.6732 - val_mse: 96.6732\n",
            "Epoch 590/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.3780 - mse: 90.3780 - val_loss: 92.0431 - val_mse: 92.0431\n",
            "Epoch 591/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.3460 - mse: 87.3460 - val_loss: 88.2840 - val_mse: 88.2840\n",
            "Epoch 592/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.0655 - mse: 86.0655 - val_loss: 96.1968 - val_mse: 96.1968\n",
            "Epoch 593/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.3711 - mse: 88.3711 - val_loss: 96.6468 - val_mse: 96.6468\n",
            "Epoch 594/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.3718 - mse: 88.3718 - val_loss: 96.0811 - val_mse: 96.0811\n",
            "Epoch 595/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.8479 - mse: 91.8479 - val_loss: 88.2860 - val_mse: 88.2860\n",
            "Epoch 596/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 83.8654 - mse: 83.8654 - val_loss: 88.4098 - val_mse: 88.4098\n",
            "Epoch 597/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.6638 - mse: 84.6638 - val_loss: 88.0983 - val_mse: 88.0983\n",
            "Epoch 598/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.1761 - mse: 87.1761 - val_loss: 90.7877 - val_mse: 90.7877\n",
            "Epoch 599/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.9360 - mse: 85.9360 - val_loss: 112.1489 - val_mse: 112.1489\n",
            "Epoch 600/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 106.2809 - mse: 106.2809 - val_loss: 113.2159 - val_mse: 113.2159\n",
            "Epoch 601/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 108.9857 - mse: 108.9857 - val_loss: 114.0152 - val_mse: 114.0152\n",
            "Epoch 602/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 106.5793 - mse: 106.5793 - val_loss: 111.8175 - val_mse: 111.8175\n",
            "Epoch 603/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.1262 - mse: 98.1262 - val_loss: 89.6702 - val_mse: 89.6702\n",
            "Epoch 604/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2972 - mse: 85.2972 - val_loss: 90.1073 - val_mse: 90.1073\n",
            "Epoch 605/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.9427 - mse: 84.9427 - val_loss: 93.5173 - val_mse: 93.5173\n",
            "Epoch 606/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.4138 - mse: 93.4138 - val_loss: 88.2194 - val_mse: 88.2194\n",
            "Epoch 607/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.0902 - mse: 85.0902 - val_loss: 87.9919 - val_mse: 87.9919\n",
            "Epoch 608/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.0255 - mse: 84.0255 - val_loss: 88.5043 - val_mse: 88.5043\n",
            "Epoch 609/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.3937 - mse: 86.3937 - val_loss: 88.2467 - val_mse: 88.2467\n",
            "Epoch 610/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.8084 - mse: 86.8084 - val_loss: 117.4015 - val_mse: 117.4015\n",
            "Epoch 611/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.6966 - mse: 93.6966 - val_loss: 89.0666 - val_mse: 89.0666\n",
            "Epoch 612/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.6232 - mse: 85.6232 - val_loss: 88.1276 - val_mse: 88.1276\n",
            "Epoch 613/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.0331 - mse: 90.0331 - val_loss: 90.1281 - val_mse: 90.1281\n",
            "Epoch 614/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.2811 - mse: 88.2811 - val_loss: 90.1678 - val_mse: 90.1678\n",
            "Epoch 615/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.0610 - mse: 85.0610 - val_loss: 87.8878 - val_mse: 87.8878\n",
            "Epoch 616/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 91.0986 - mse: 91.0986 - val_loss: 106.2401 - val_mse: 106.2401\n",
            "Epoch 617/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 97.6606 - mse: 97.6606 - val_loss: 95.4459 - val_mse: 95.4459\n",
            "Epoch 618/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.1894 - mse: 92.1894 - val_loss: 106.0383 - val_mse: 106.0383\n",
            "Epoch 619/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.5540 - mse: 96.5540 - val_loss: 99.6419 - val_mse: 99.6419\n",
            "Epoch 620/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 130.6224 - mse: 130.6224 - val_loss: 152.3756 - val_mse: 152.3756\n",
            "Epoch 621/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 138.0811 - mse: 138.0811 - val_loss: 153.1307 - val_mse: 153.1307\n",
            "Epoch 622/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 110.9685 - mse: 110.9685 - val_loss: 113.6750 - val_mse: 113.6750\n",
            "Epoch 623/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.0328 - mse: 98.0328 - val_loss: 99.3993 - val_mse: 99.3993\n",
            "Epoch 624/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.3546 - mse: 89.3546 - val_loss: 94.3763 - val_mse: 94.3763\n",
            "Epoch 625/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 87.8510 - mse: 87.8510 - val_loss: 93.3432 - val_mse: 93.3432\n",
            "Epoch 626/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.9796 - mse: 87.9796 - val_loss: 89.6843 - val_mse: 89.6843\n",
            "Epoch 627/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.9618 - mse: 87.9618 - val_loss: 105.2863 - val_mse: 105.2863\n",
            "Epoch 628/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.5326 - mse: 90.5326 - val_loss: 88.9676 - val_mse: 88.9676\n",
            "Epoch 629/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.5376 - mse: 85.5376 - val_loss: 106.4054 - val_mse: 106.4054\n",
            "Epoch 630/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.8259 - mse: 91.8259 - val_loss: 87.8403 - val_mse: 87.8403\n",
            "Epoch 631/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 90.0827 - mse: 90.0827 - val_loss: 87.9351 - val_mse: 87.9351\n",
            "Epoch 632/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.7731 - mse: 90.7731 - val_loss: 95.3794 - val_mse: 95.3794\n",
            "Epoch 633/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.5283 - mse: 88.5283 - val_loss: 90.5053 - val_mse: 90.5053\n",
            "Epoch 634/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 86.9522 - mse: 86.9522 - val_loss: 94.6407 - val_mse: 94.6407\n",
            "Epoch 635/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.2912 - mse: 90.2912 - val_loss: 109.1162 - val_mse: 109.1162\n",
            "Epoch 636/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.2032 - mse: 92.2032 - val_loss: 90.1465 - val_mse: 90.1465\n",
            "Epoch 637/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.6748 - mse: 89.6748 - val_loss: 104.6213 - val_mse: 104.6213\n",
            "Epoch 638/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.8761 - mse: 90.8761 - val_loss: 96.3495 - val_mse: 96.3495\n",
            "Epoch 639/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.9941 - mse: 96.9941 - val_loss: 107.2252 - val_mse: 107.2252\n",
            "Epoch 640/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.0995 - mse: 93.0995 - val_loss: 105.6531 - val_mse: 105.6531\n",
            "Epoch 641/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.4630 - mse: 97.4630 - val_loss: 93.8548 - val_mse: 93.8548\n",
            "Epoch 642/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.8962 - mse: 86.8962 - val_loss: 87.9319 - val_mse: 87.9319\n",
            "Epoch 643/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.0077 - mse: 84.0077 - val_loss: 89.8863 - val_mse: 89.8863\n",
            "Epoch 644/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.6952 - mse: 89.6952 - val_loss: 93.6720 - val_mse: 93.6720\n",
            "Epoch 645/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.9817 - mse: 88.9817 - val_loss: 103.8332 - val_mse: 103.8332\n",
            "Epoch 646/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.3359 - mse: 95.3359 - val_loss: 100.9125 - val_mse: 100.9125\n",
            "Epoch 647/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.7593 - mse: 87.7593 - val_loss: 88.6603 - val_mse: 88.6603\n",
            "Epoch 648/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.2546 - mse: 88.2546 - val_loss: 88.0135 - val_mse: 88.0135\n",
            "Epoch 649/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 91.2542 - mse: 91.2542 - val_loss: 89.3584 - val_mse: 89.3584\n",
            "Epoch 650/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.3064 - mse: 88.3064 - val_loss: 88.7123 - val_mse: 88.7123\n",
            "Epoch 651/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.0195 - mse: 87.0195 - val_loss: 98.4328 - val_mse: 98.4328\n",
            "Epoch 652/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 91.2119 - mse: 91.2119 - val_loss: 113.8676 - val_mse: 113.8676\n",
            "Epoch 653/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 94.0346 - mse: 94.0346 - val_loss: 99.8992 - val_mse: 99.8992\n",
            "Epoch 654/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.5790 - mse: 88.5790 - val_loss: 87.9122 - val_mse: 87.9122\n",
            "Epoch 655/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.5255 - mse: 89.5255 - val_loss: 88.2097 - val_mse: 88.2097\n",
            "Epoch 656/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2283 - mse: 85.2283 - val_loss: 89.0779 - val_mse: 89.0779\n",
            "Epoch 657/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2130 - mse: 85.2130 - val_loss: 88.9679 - val_mse: 88.9679\n",
            "Epoch 658/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.1486 - mse: 87.1486 - val_loss: 89.4844 - val_mse: 89.4844\n",
            "Epoch 659/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.0471 - mse: 86.0471 - val_loss: 88.1579 - val_mse: 88.1579\n",
            "Epoch 660/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.1266 - mse: 89.1266 - val_loss: 87.5938 - val_mse: 87.5938\n",
            "Epoch 661/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 113.8276 - mse: 113.8276 - val_loss: 94.0786 - val_mse: 94.0786\n",
            "Epoch 662/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 104.5829 - mse: 104.5829 - val_loss: 88.7535 - val_mse: 88.7535\n",
            "Epoch 663/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.6874 - mse: 88.6874 - val_loss: 107.9454 - val_mse: 107.9454\n",
            "Epoch 664/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.2278 - mse: 96.2278 - val_loss: 113.6464 - val_mse: 113.6464\n",
            "Epoch 665/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.7889 - mse: 97.7889 - val_loss: 103.4490 - val_mse: 103.4490\n",
            "Epoch 666/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.0426 - mse: 95.0426 - val_loss: 97.1706 - val_mse: 97.1706\n",
            "Epoch 667/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 107.8753 - mse: 107.8753 - val_loss: 89.8363 - val_mse: 89.8363\n",
            "Epoch 668/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.4038 - mse: 89.4038 - val_loss: 89.8374 - val_mse: 89.8374\n",
            "Epoch 669/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.8082 - mse: 89.8082 - val_loss: 101.2444 - val_mse: 101.2444\n",
            "Epoch 670/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.5649 - mse: 99.5649 - val_loss: 97.6473 - val_mse: 97.6473\n",
            "Epoch 671/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 90.7030 - mse: 90.7030 - val_loss: 95.4800 - val_mse: 95.4800\n",
            "Epoch 672/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 85.6846 - mse: 85.6846 - val_loss: 94.5183 - val_mse: 94.5183\n",
            "Epoch 673/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 92.1449 - mse: 92.1449 - val_loss: 105.0251 - val_mse: 105.0251\n",
            "Epoch 674/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 88.3585 - mse: 88.3585 - val_loss: 87.4874 - val_mse: 87.4874\n",
            "Epoch 675/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.3192 - mse: 85.3192 - val_loss: 107.1099 - val_mse: 107.1099\n",
            "Epoch 676/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.9954 - mse: 95.9954 - val_loss: 103.4138 - val_mse: 103.4138\n",
            "Epoch 677/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.7821 - mse: 89.7821 - val_loss: 90.0319 - val_mse: 90.0319\n",
            "Epoch 678/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.1621 - mse: 90.1621 - val_loss: 105.3307 - val_mse: 105.3307\n",
            "Epoch 679/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.6295 - mse: 93.6295 - val_loss: 120.8565 - val_mse: 120.8565\n",
            "Epoch 680/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 97.4425 - mse: 97.4425 - val_loss: 90.1410 - val_mse: 90.1410\n",
            "Epoch 681/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.5905 - mse: 88.5905 - val_loss: 105.1898 - val_mse: 105.1898\n",
            "Epoch 682/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.5670 - mse: 88.5670 - val_loss: 93.7823 - val_mse: 93.7823\n",
            "Epoch 683/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.6675 - mse: 89.6675 - val_loss: 93.8029 - val_mse: 93.8029\n",
            "Epoch 684/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.1520 - mse: 85.1520 - val_loss: 89.8380 - val_mse: 89.8380\n",
            "Epoch 685/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.3124 - mse: 83.3124 - val_loss: 87.4629 - val_mse: 87.4629\n",
            "Epoch 686/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.2389 - mse: 84.2389 - val_loss: 91.1286 - val_mse: 91.1286\n",
            "Epoch 687/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.9998 - mse: 83.9998 - val_loss: 87.3747 - val_mse: 87.3747\n",
            "Epoch 688/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.7276 - mse: 85.7276 - val_loss: 87.4718 - val_mse: 87.4718\n",
            "Epoch 689/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.7232 - mse: 85.7232 - val_loss: 102.7593 - val_mse: 102.7593\n",
            "Epoch 690/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.3297 - mse: 92.3297 - val_loss: 110.0639 - val_mse: 110.0639\n",
            "Epoch 691/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 100.3600 - mse: 100.3600 - val_loss: 91.5488 - val_mse: 91.5488\n",
            "Epoch 692/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.9767 - mse: 96.9767 - val_loss: 101.6934 - val_mse: 101.6934\n",
            "Epoch 693/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.8037 - mse: 91.8037 - val_loss: 94.5080 - val_mse: 94.5080\n",
            "Epoch 694/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.4810 - mse: 90.4810 - val_loss: 110.3948 - val_mse: 110.3948\n",
            "Epoch 695/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.4006 - mse: 99.4006 - val_loss: 152.3341 - val_mse: 152.3341\n",
            "Epoch 696/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 121.5331 - mse: 121.5331 - val_loss: 140.1181 - val_mse: 140.1181\n",
            "Epoch 697/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 108.5940 - mse: 108.5940 - val_loss: 97.9373 - val_mse: 97.9373\n",
            "Epoch 698/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 92.4356 - mse: 92.4356 - val_loss: 96.1001 - val_mse: 96.1001\n",
            "Epoch 699/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.9353 - mse: 93.9353 - val_loss: 89.9587 - val_mse: 89.9587\n",
            "Epoch 700/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.8971 - mse: 90.8971 - val_loss: 90.8379 - val_mse: 90.8379\n",
            "Epoch 701/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.7390 - mse: 93.7390 - val_loss: 88.9562 - val_mse: 88.9562\n",
            "Epoch 702/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.4786 - mse: 85.4786 - val_loss: 87.4614 - val_mse: 87.4614\n",
            "Epoch 703/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.1444 - mse: 83.1444 - val_loss: 91.9901 - val_mse: 91.9901\n",
            "Epoch 704/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.2113 - mse: 94.2113 - val_loss: 88.2033 - val_mse: 88.2033\n",
            "Epoch 705/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 85.3010 - mse: 85.3010 - val_loss: 93.5687 - val_mse: 93.5687\n",
            "Epoch 706/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 94.1249 - mse: 94.1249 - val_loss: 94.8095 - val_mse: 94.8095\n",
            "Epoch 707/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.9271 - mse: 88.9271 - val_loss: 87.1519 - val_mse: 87.1519\n",
            "Epoch 708/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.9737 - mse: 83.9737 - val_loss: 87.1453 - val_mse: 87.1453\n",
            "Epoch 709/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.8121 - mse: 83.8121 - val_loss: 87.0487 - val_mse: 87.0487\n",
            "Epoch 710/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.5517 - mse: 84.5517 - val_loss: 91.5113 - val_mse: 91.5113\n",
            "Epoch 711/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 95.6667 - mse: 95.6667 - val_loss: 93.4302 - val_mse: 93.4302\n",
            "Epoch 712/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 107.6632 - mse: 107.6632 - val_loss: 111.7749 - val_mse: 111.7749\n",
            "Epoch 713/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 126.7648 - mse: 126.7648 - val_loss: 92.8095 - val_mse: 92.8095\n",
            "Epoch 714/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.3508 - mse: 97.3508 - val_loss: 108.9446 - val_mse: 108.9446\n",
            "Epoch 715/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.6042 - mse: 89.6042 - val_loss: 89.2816 - val_mse: 89.2816\n",
            "Epoch 716/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.5178 - mse: 86.5178 - val_loss: 87.7071 - val_mse: 87.7071\n",
            "Epoch 717/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.6598 - mse: 85.6598 - val_loss: 88.5885 - val_mse: 88.5885\n",
            "Epoch 718/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.0726 - mse: 100.0726 - val_loss: 99.3776 - val_mse: 99.3776\n",
            "Epoch 719/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.3736 - mse: 97.3736 - val_loss: 97.4891 - val_mse: 97.4891\n",
            "Epoch 720/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.7347 - mse: 87.7347 - val_loss: 113.7448 - val_mse: 113.7448\n",
            "Epoch 721/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.9711 - mse: 92.9711 - val_loss: 90.0167 - val_mse: 90.0167\n",
            "Epoch 722/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.1184 - mse: 86.1184 - val_loss: 87.1121 - val_mse: 87.1121\n",
            "Epoch 723/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.4520 - mse: 86.4520 - val_loss: 90.7986 - val_mse: 90.7986\n",
            "Epoch 724/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 90.8762 - mse: 90.8762 - val_loss: 87.9480 - val_mse: 87.9480\n",
            "Epoch 725/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.3128 - mse: 87.3128 - val_loss: 90.9465 - val_mse: 90.9465\n",
            "Epoch 726/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.2895 - mse: 86.2895 - val_loss: 91.2853 - val_mse: 91.2853\n",
            "Epoch 727/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.8773 - mse: 88.8773 - val_loss: 94.0978 - val_mse: 94.0978\n",
            "Epoch 728/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.8366 - mse: 89.8366 - val_loss: 96.8978 - val_mse: 96.8978\n",
            "Epoch 729/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.3741 - mse: 86.3741 - val_loss: 97.2178 - val_mse: 97.2178\n",
            "Epoch 730/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.2182 - mse: 86.2182 - val_loss: 118.7909 - val_mse: 118.7909\n",
            "Epoch 731/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 94.5043 - mse: 94.5043 - val_loss: 87.7821 - val_mse: 87.7821\n",
            "Epoch 732/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.4651 - mse: 83.4651 - val_loss: 88.3006 - val_mse: 88.3006\n",
            "Epoch 733/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.1889 - mse: 88.1889 - val_loss: 92.0735 - val_mse: 92.0735\n",
            "Epoch 734/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.8738 - mse: 89.8738 - val_loss: 88.6732 - val_mse: 88.6732\n",
            "Epoch 735/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.7279 - mse: 84.7279 - val_loss: 87.1036 - val_mse: 87.1036\n",
            "Epoch 736/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.3640 - mse: 90.3640 - val_loss: 95.3308 - val_mse: 95.3308\n",
            "Epoch 737/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.0060 - mse: 86.0060 - val_loss: 98.2840 - val_mse: 98.2840\n",
            "Epoch 738/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.6966 - mse: 88.6966 - val_loss: 116.8031 - val_mse: 116.8031\n",
            "Epoch 739/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.4866 - mse: 96.4866 - val_loss: 95.4460 - val_mse: 95.4460\n",
            "Epoch 740/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.8000 - mse: 87.8000 - val_loss: 87.2728 - val_mse: 87.2728\n",
            "Epoch 741/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.4289 - mse: 94.4289 - val_loss: 94.7470 - val_mse: 94.7470\n",
            "Epoch 742/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 102.8427 - mse: 102.8427 - val_loss: 124.1037 - val_mse: 124.1037\n",
            "Epoch 743/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 96.0183 - mse: 96.0183 - val_loss: 101.1673 - val_mse: 101.1673\n",
            "Epoch 744/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.4643 - mse: 87.4643 - val_loss: 87.4944 - val_mse: 87.4944\n",
            "Epoch 745/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.7854 - mse: 84.7854 - val_loss: 115.4938 - val_mse: 115.4938\n",
            "Epoch 746/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.9263 - mse: 103.9263 - val_loss: 134.7121 - val_mse: 134.7121\n",
            "Epoch 747/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.2565 - mse: 103.2565 - val_loss: 104.8269 - val_mse: 104.8269\n",
            "Epoch 748/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.3342 - mse: 88.3342 - val_loss: 97.8008 - val_mse: 97.8008\n",
            "Epoch 749/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 100.2749 - mse: 100.2749 - val_loss: 127.4282 - val_mse: 127.4282\n",
            "Epoch 750/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.5777 - mse: 103.5777 - val_loss: 90.6858 - val_mse: 90.6858\n",
            "Epoch 751/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.5174 - mse: 83.5174 - val_loss: 87.1989 - val_mse: 87.1989\n",
            "Epoch 752/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.9241 - mse: 84.9241 - val_loss: 115.9188 - val_mse: 115.9188\n",
            "Epoch 753/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.7080 - mse: 98.7080 - val_loss: 100.7801 - val_mse: 100.7801\n",
            "Epoch 754/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.8579 - mse: 88.8579 - val_loss: 90.2578 - val_mse: 90.2578\n",
            "Epoch 755/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.8658 - mse: 83.8658 - val_loss: 91.8653 - val_mse: 91.8653\n",
            "Epoch 756/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.6517 - mse: 90.6517 - val_loss: 87.0022 - val_mse: 87.0022\n",
            "Epoch 757/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.9692 - mse: 89.9692 - val_loss: 90.7865 - val_mse: 90.7865\n",
            "Epoch 758/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.3108 - mse: 87.3108 - val_loss: 87.0650 - val_mse: 87.0650\n",
            "Epoch 759/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.2335 - mse: 83.2335 - val_loss: 93.2114 - val_mse: 93.2114\n",
            "Epoch 760/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 85.6909 - mse: 85.6909 - val_loss: 91.0616 - val_mse: 91.0616\n",
            "Epoch 761/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.4798 - mse: 84.4798 - val_loss: 86.9138 - val_mse: 86.9138\n",
            "Epoch 762/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.9846 - mse: 83.9846 - val_loss: 93.3050 - val_mse: 93.3050\n",
            "Epoch 763/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.8096 - mse: 87.8096 - val_loss: 94.2622 - val_mse: 94.2622\n",
            "Epoch 764/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.7188 - mse: 92.7188 - val_loss: 87.4118 - val_mse: 87.4118\n",
            "Epoch 765/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.6080 - mse: 84.6080 - val_loss: 92.1629 - val_mse: 92.1629\n",
            "Epoch 766/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.7098 - mse: 95.7098 - val_loss: 97.5352 - val_mse: 97.5352\n",
            "Epoch 767/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 107.4918 - mse: 107.4918 - val_loss: 93.1144 - val_mse: 93.1144\n",
            "Epoch 768/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 111.9533 - mse: 111.9533 - val_loss: 112.4722 - val_mse: 112.4722\n",
            "Epoch 769/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.7294 - mse: 101.7294 - val_loss: 115.2764 - val_mse: 115.2764\n",
            "Epoch 770/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.8524 - mse: 98.8524 - val_loss: 88.2639 - val_mse: 88.2639\n",
            "Epoch 771/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 98.1828 - mse: 98.1828 - val_loss: 99.6746 - val_mse: 99.6746\n",
            "Epoch 772/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 105.7193 - mse: 105.7193 - val_loss: 113.0175 - val_mse: 113.0175\n",
            "Epoch 773/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 103.3190 - mse: 103.3190 - val_loss: 126.0660 - val_mse: 126.0660\n",
            "Epoch 774/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.9326 - mse: 103.9326 - val_loss: 88.2365 - val_mse: 88.2365\n",
            "Epoch 775/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 104.7765 - mse: 104.7765 - val_loss: 90.1407 - val_mse: 90.1407\n",
            "Epoch 776/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.3738 - mse: 90.3738 - val_loss: 118.8786 - val_mse: 118.8786\n",
            "Epoch 777/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 104.1833 - mse: 104.1833 - val_loss: 97.0665 - val_mse: 97.0665\n",
            "Epoch 778/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.5760 - mse: 89.5760 - val_loss: 89.0068 - val_mse: 89.0068\n",
            "Epoch 779/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.0974 - mse: 89.0974 - val_loss: 102.3338 - val_mse: 102.3338\n",
            "Epoch 780/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.7450 - mse: 90.7450 - val_loss: 87.1426 - val_mse: 87.1426\n",
            "Epoch 781/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2536 - mse: 85.2536 - val_loss: 87.0981 - val_mse: 87.0981\n",
            "Epoch 782/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.0492 - mse: 87.0492 - val_loss: 118.8595 - val_mse: 118.8595\n",
            "Epoch 783/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.8108 - mse: 90.8108 - val_loss: 97.0867 - val_mse: 97.0867\n",
            "Epoch 784/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.1346 - mse: 90.1346 - val_loss: 98.2304 - val_mse: 98.2304\n",
            "Epoch 785/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.9460 - mse: 87.9460 - val_loss: 91.8404 - val_mse: 91.8404\n",
            "Epoch 786/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.9017 - mse: 85.9017 - val_loss: 90.2136 - val_mse: 90.2136\n",
            "Epoch 787/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.4159 - mse: 85.4159 - val_loss: 90.5352 - val_mse: 90.5352\n",
            "Epoch 788/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.9503 - mse: 89.9503 - val_loss: 121.2354 - val_mse: 121.2354\n",
            "Epoch 789/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.8420 - mse: 98.8420 - val_loss: 99.6475 - val_mse: 99.6475\n",
            "Epoch 790/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.0495 - mse: 90.0495 - val_loss: 86.7817 - val_mse: 86.7817\n",
            "Epoch 791/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.7363 - mse: 85.7363 - val_loss: 88.7959 - val_mse: 88.7959\n",
            "Epoch 792/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 83.1262 - mse: 83.1262 - val_loss: 89.5657 - val_mse: 89.5657\n",
            "Epoch 793/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.0435 - mse: 83.0435 - val_loss: 86.8456 - val_mse: 86.8456\n",
            "Epoch 794/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.6670 - mse: 86.6670 - val_loss: 88.3967 - val_mse: 88.3967\n",
            "Epoch 795/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.1054 - mse: 88.1054 - val_loss: 100.6966 - val_mse: 100.6966\n",
            "Epoch 796/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.8681 - mse: 99.8681 - val_loss: 91.1786 - val_mse: 91.1786\n",
            "Epoch 797/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.6034 - mse: 88.6034 - val_loss: 89.6051 - val_mse: 89.6051\n",
            "Epoch 798/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.5704 - mse: 85.5704 - val_loss: 90.2659 - val_mse: 90.2659\n",
            "Epoch 799/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.9142 - mse: 83.9142 - val_loss: 99.7993 - val_mse: 99.7993\n",
            "Epoch 800/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 88.1486 - mse: 88.1486 - val_loss: 95.1622 - val_mse: 95.1622\n",
            "Epoch 801/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.5698 - mse: 87.5698 - val_loss: 86.8861 - val_mse: 86.8861\n",
            "Epoch 802/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2574 - mse: 85.2574 - val_loss: 91.2952 - val_mse: 91.2952\n",
            "Epoch 803/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.7503 - mse: 83.7503 - val_loss: 98.8304 - val_mse: 98.8304\n",
            "Epoch 804/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.9623 - mse: 86.9623 - val_loss: 88.4367 - val_mse: 88.4367\n",
            "Epoch 805/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.5713 - mse: 89.5713 - val_loss: 99.0871 - val_mse: 99.0871\n",
            "Epoch 806/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.8062 - mse: 89.8062 - val_loss: 99.1400 - val_mse: 99.1400\n",
            "Epoch 807/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.5254 - mse: 91.5254 - val_loss: 117.1774 - val_mse: 117.1774\n",
            "Epoch 808/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.4247 - mse: 98.4247 - val_loss: 111.9984 - val_mse: 111.9984\n",
            "Epoch 809/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 94.8032 - mse: 94.8032 - val_loss: 88.9343 - val_mse: 88.9343\n",
            "Epoch 810/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 103.1026 - mse: 103.1026 - val_loss: 102.6452 - val_mse: 102.6452\n",
            "Epoch 811/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.5030 - mse: 95.5030 - val_loss: 133.8781 - val_mse: 133.8781\n",
            "Epoch 812/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.1734 - mse: 104.1734 - val_loss: 106.6809 - val_mse: 106.6809\n",
            "Epoch 813/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 89.7232 - mse: 89.7232 - val_loss: 86.4998 - val_mse: 86.4998\n",
            "Epoch 814/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.8969 - mse: 82.8969 - val_loss: 89.6761 - val_mse: 89.6761\n",
            "Epoch 815/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.2751 - mse: 86.2751 - val_loss: 86.2468 - val_mse: 86.2468\n",
            "Epoch 816/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.0569 - mse: 83.0569 - val_loss: 87.6651 - val_mse: 87.6651\n",
            "Epoch 817/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.8496 - mse: 82.8496 - val_loss: 92.8696 - val_mse: 92.8696\n",
            "Epoch 818/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.3650 - mse: 89.3650 - val_loss: 98.0084 - val_mse: 98.0084\n",
            "Epoch 819/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 93.6593 - mse: 93.6593 - val_loss: 96.6831 - val_mse: 96.6831\n",
            "Epoch 820/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.5591 - mse: 88.5591 - val_loss: 89.0362 - val_mse: 89.0362\n",
            "Epoch 821/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2889 - mse: 85.2889 - val_loss: 99.8730 - val_mse: 99.8730\n",
            "Epoch 822/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.9876 - mse: 93.9876 - val_loss: 96.4274 - val_mse: 96.4274\n",
            "Epoch 823/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.7398 - mse: 90.7398 - val_loss: 86.4495 - val_mse: 86.4495\n",
            "Epoch 824/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.4722 - mse: 83.4722 - val_loss: 86.9937 - val_mse: 86.9937\n",
            "Epoch 825/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.1965 - mse: 82.1965 - val_loss: 86.7169 - val_mse: 86.7169\n",
            "Epoch 826/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.3643 - mse: 84.3643 - val_loss: 86.8145 - val_mse: 86.8145\n",
            "Epoch 827/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.0309 - mse: 82.0309 - val_loss: 86.0734 - val_mse: 86.0734\n",
            "Epoch 828/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.4404 - mse: 83.4404 - val_loss: 97.0399 - val_mse: 97.0399\n",
            "Epoch 829/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.6753 - mse: 89.6753 - val_loss: 103.3562 - val_mse: 103.3562\n",
            "Epoch 830/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 90.8757 - mse: 90.8757 - val_loss: 94.6288 - val_mse: 94.6288\n",
            "Epoch 831/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.6147 - mse: 87.6147 - val_loss: 86.2732 - val_mse: 86.2732\n",
            "Epoch 832/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.9093 - mse: 84.9093 - val_loss: 87.6858 - val_mse: 87.6858\n",
            "Epoch 833/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.2576 - mse: 85.2576 - val_loss: 100.9838 - val_mse: 100.9838\n",
            "Epoch 834/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.8924 - mse: 86.8924 - val_loss: 98.2086 - val_mse: 98.2086\n",
            "Epoch 835/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.3446 - mse: 87.3446 - val_loss: 97.2356 - val_mse: 97.2356\n",
            "Epoch 836/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.8165 - mse: 90.8165 - val_loss: 102.8272 - val_mse: 102.8272\n",
            "Epoch 837/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.9390 - mse: 93.9390 - val_loss: 105.3813 - val_mse: 105.3813\n",
            "Epoch 838/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.2255 - mse: 91.2255 - val_loss: 104.3668 - val_mse: 104.3668\n",
            "Epoch 839/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.8669 - mse: 86.8669 - val_loss: 88.0782 - val_mse: 88.0782\n",
            "Epoch 840/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.1491 - mse: 84.1491 - val_loss: 96.4302 - val_mse: 96.4302\n",
            "Epoch 841/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.3288 - mse: 85.3288 - val_loss: 87.2888 - val_mse: 87.2888\n",
            "Epoch 842/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.6605 - mse: 86.6605 - val_loss: 88.1072 - val_mse: 88.1072\n",
            "Epoch 843/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.5319 - mse: 85.5319 - val_loss: 86.6775 - val_mse: 86.6775\n",
            "Epoch 844/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.4032 - mse: 82.4032 - val_loss: 86.5389 - val_mse: 86.5389\n",
            "Epoch 845/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.7792 - mse: 81.7792 - val_loss: 87.6175 - val_mse: 87.6175\n",
            "Epoch 846/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.0171 - mse: 87.0171 - val_loss: 101.3486 - val_mse: 101.3486\n",
            "Epoch 847/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.2023 - mse: 89.2023 - val_loss: 89.7866 - val_mse: 89.7866\n",
            "Epoch 848/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.7466 - mse: 90.7466 - val_loss: 91.5188 - val_mse: 91.5188\n",
            "Epoch 849/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 88.3111 - mse: 88.3111 - val_loss: 102.9937 - val_mse: 102.9937\n",
            "Epoch 850/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.8822 - mse: 87.8822 - val_loss: 87.9182 - val_mse: 87.9182\n",
            "Epoch 851/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.9119 - mse: 87.9119 - val_loss: 92.8971 - val_mse: 92.8971\n",
            "Epoch 852/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.0966 - mse: 85.0966 - val_loss: 93.4919 - val_mse: 93.4919\n",
            "Epoch 853/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.5009 - mse: 85.5009 - val_loss: 87.4197 - val_mse: 87.4197\n",
            "Epoch 854/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.9736 - mse: 81.9736 - val_loss: 88.9155 - val_mse: 88.9155\n",
            "Epoch 855/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 92.9105 - mse: 92.9105 - val_loss: 93.8680 - val_mse: 93.8680\n",
            "Epoch 856/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.4216 - mse: 97.4216 - val_loss: 98.8247 - val_mse: 98.8247\n",
            "Epoch 857/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.0706 - mse: 94.0706 - val_loss: 110.5667 - val_mse: 110.5667\n",
            "Epoch 858/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 96.7368 - mse: 96.7368 - val_loss: 97.8465 - val_mse: 97.8465\n",
            "Epoch 859/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 89.7645 - mse: 89.7645 - val_loss: 86.0070 - val_mse: 86.0070\n",
            "Epoch 860/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.5608 - mse: 92.5608 - val_loss: 86.1846 - val_mse: 86.1846\n",
            "Epoch 861/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.0652 - mse: 82.0652 - val_loss: 86.7993 - val_mse: 86.7993\n",
            "Epoch 862/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.3159 - mse: 81.3159 - val_loss: 87.1680 - val_mse: 87.1680\n",
            "Epoch 863/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.2922 - mse: 82.2922 - val_loss: 85.9809 - val_mse: 85.9809\n",
            "Epoch 864/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.5210 - mse: 83.5210 - val_loss: 85.9070 - val_mse: 85.9070\n",
            "Epoch 865/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 91.6259 - mse: 91.6259 - val_loss: 91.2091 - val_mse: 91.2091\n",
            "Epoch 866/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 90.8483 - mse: 90.8483 - val_loss: 116.6772 - val_mse: 116.6772\n",
            "Epoch 867/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 112.4833 - mse: 112.4833 - val_loss: 151.7529 - val_mse: 151.7529\n",
            "Epoch 868/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 112.0094 - mse: 112.0094 - val_loss: 118.3803 - val_mse: 118.3803\n",
            "Epoch 869/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.5309 - mse: 101.5309 - val_loss: 87.5598 - val_mse: 87.5598\n",
            "Epoch 870/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.3834 - mse: 91.3834 - val_loss: 103.8594 - val_mse: 103.8594\n",
            "Epoch 871/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.8911 - mse: 88.8911 - val_loss: 94.1463 - val_mse: 94.1463\n",
            "Epoch 872/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.9166 - mse: 84.9166 - val_loss: 85.7136 - val_mse: 85.7136\n",
            "Epoch 873/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.8775 - mse: 82.8775 - val_loss: 86.0040 - val_mse: 86.0040\n",
            "Epoch 874/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.4852 - mse: 81.4852 - val_loss: 85.9041 - val_mse: 85.9041\n",
            "Epoch 875/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.2083 - mse: 83.2083 - val_loss: 86.3735 - val_mse: 86.3735\n",
            "Epoch 876/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.4006 - mse: 84.4006 - val_loss: 85.7118 - val_mse: 85.7118\n",
            "Epoch 877/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.0935 - mse: 86.0935 - val_loss: 85.7909 - val_mse: 85.7909\n",
            "Epoch 878/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 92.8836 - mse: 92.8836 - val_loss: 104.7445 - val_mse: 104.7445\n",
            "Epoch 879/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 90.0446 - mse: 90.0446 - val_loss: 86.0981 - val_mse: 86.0981\n",
            "Epoch 880/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.5100 - mse: 82.5100 - val_loss: 112.1403 - val_mse: 112.1403\n",
            "Epoch 881/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 104.2808 - mse: 104.2808 - val_loss: 142.2798 - val_mse: 142.2798\n",
            "Epoch 882/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 106.2116 - mse: 106.2116 - val_loss: 86.0299 - val_mse: 86.0299\n",
            "Epoch 883/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.6424 - mse: 81.6424 - val_loss: 85.6309 - val_mse: 85.6309\n",
            "Epoch 884/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 82.4138 - mse: 82.4138 - val_loss: 97.5092 - val_mse: 97.5092\n",
            "Epoch 885/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 89.1978 - mse: 89.1978 - val_loss: 95.3651 - val_mse: 95.3651\n",
            "Epoch 886/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.1051 - mse: 89.1051 - val_loss: 92.9082 - val_mse: 92.9082\n",
            "Epoch 887/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.0840 - mse: 89.0840 - val_loss: 86.5290 - val_mse: 86.5290\n",
            "Epoch 888/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.6200 - mse: 88.6200 - val_loss: 86.6872 - val_mse: 86.6872\n",
            "Epoch 889/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.7644 - mse: 83.7644 - val_loss: 85.8401 - val_mse: 85.8401\n",
            "Epoch 890/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.8864 - mse: 88.8864 - val_loss: 142.2641 - val_mse: 142.2641\n",
            "Epoch 891/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.3547 - mse: 103.3547 - val_loss: 89.4094 - val_mse: 89.4094\n",
            "Epoch 892/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.3102 - mse: 98.3102 - val_loss: 88.1873 - val_mse: 88.1873\n",
            "Epoch 893/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.2861 - mse: 87.2861 - val_loss: 90.6107 - val_mse: 90.6107\n",
            "Epoch 894/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.0078 - mse: 88.0078 - val_loss: 90.2081 - val_mse: 90.2081\n",
            "Epoch 895/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.4450 - mse: 83.4450 - val_loss: 88.5653 - val_mse: 88.5653\n",
            "Epoch 896/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.8683 - mse: 92.8683 - val_loss: 103.0460 - val_mse: 103.0460\n",
            "Epoch 897/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 94.1986 - mse: 94.1986 - val_loss: 111.2571 - val_mse: 111.2571\n",
            "Epoch 898/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.8927 - mse: 91.8927 - val_loss: 98.5578 - val_mse: 98.5578\n",
            "Epoch 899/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 94.4284 - mse: 94.4284 - val_loss: 85.8752 - val_mse: 85.8752\n",
            "Epoch 900/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.4090 - mse: 98.4090 - val_loss: 100.4380 - val_mse: 100.4380\n",
            "Epoch 901/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 94.2123 - mse: 94.2123 - val_loss: 114.1738 - val_mse: 114.1738\n",
            "Epoch 902/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.2322 - mse: 89.2322 - val_loss: 92.3011 - val_mse: 92.3011\n",
            "Epoch 903/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.1470 - mse: 84.1470 - val_loss: 86.0922 - val_mse: 86.0922\n",
            "Epoch 904/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.0394 - mse: 83.0394 - val_loss: 85.6140 - val_mse: 85.6140\n",
            "Epoch 905/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.8136 - mse: 80.8136 - val_loss: 86.7330 - val_mse: 86.7330\n",
            "Epoch 906/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.5117 - mse: 83.5117 - val_loss: 91.4709 - val_mse: 91.4709\n",
            "Epoch 907/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.6092 - mse: 83.6092 - val_loss: 85.9823 - val_mse: 85.9823\n",
            "Epoch 908/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.4877 - mse: 83.4877 - val_loss: 86.7196 - val_mse: 86.7196\n",
            "Epoch 909/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 81.7712 - mse: 81.7712 - val_loss: 89.0110 - val_mse: 89.0110\n",
            "Epoch 910/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.0670 - mse: 87.0670 - val_loss: 103.7075 - val_mse: 103.7075\n",
            "Epoch 911/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.9081 - mse: 88.9081 - val_loss: 87.3770 - val_mse: 87.3770\n",
            "Epoch 912/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.1868 - mse: 95.1868 - val_loss: 89.0868 - val_mse: 89.0868\n",
            "Epoch 913/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.1704 - mse: 101.1704 - val_loss: 128.8320 - val_mse: 128.8320\n",
            "Epoch 914/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 106.9753 - mse: 106.9753 - val_loss: 97.7123 - val_mse: 97.7123\n",
            "Epoch 915/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.9799 - mse: 93.9799 - val_loss: 86.5995 - val_mse: 86.5995\n",
            "Epoch 916/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.1719 - mse: 82.1719 - val_loss: 88.0981 - val_mse: 88.0981\n",
            "Epoch 917/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.9906 - mse: 84.9906 - val_loss: 100.1518 - val_mse: 100.1518\n",
            "Epoch 918/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 86.1959 - mse: 86.1959 - val_loss: 87.5444 - val_mse: 87.5444\n",
            "Epoch 919/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 82.1906 - mse: 82.1906 - val_loss: 86.9194 - val_mse: 86.9194\n",
            "Epoch 920/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 85.7476 - mse: 85.7476 - val_loss: 109.6062 - val_mse: 109.6062\n",
            "Epoch 921/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.4497 - mse: 90.4497 - val_loss: 89.9121 - val_mse: 89.9121\n",
            "Epoch 922/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.9656 - mse: 90.9656 - val_loss: 85.5207 - val_mse: 85.5207\n",
            "Epoch 923/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.4965 - mse: 87.4965 - val_loss: 85.9993 - val_mse: 85.9993\n",
            "Epoch 924/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.2865 - mse: 84.2865 - val_loss: 86.2100 - val_mse: 86.2100\n",
            "Epoch 925/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 81.8458 - mse: 81.8458 - val_loss: 104.0920 - val_mse: 104.0920\n",
            "Epoch 926/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.6622 - mse: 88.6622 - val_loss: 87.5562 - val_mse: 87.5562\n",
            "Epoch 927/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.5780 - mse: 88.5780 - val_loss: 87.5868 - val_mse: 87.5868\n",
            "Epoch 928/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.0318 - mse: 86.0318 - val_loss: 116.2049 - val_mse: 116.2049\n",
            "Epoch 929/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 98.1791 - mse: 98.1791 - val_loss: 90.7162 - val_mse: 90.7162\n",
            "Epoch 930/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.7366 - mse: 90.7366 - val_loss: 92.0608 - val_mse: 92.0608\n",
            "Epoch 931/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 94.2761 - mse: 94.2761 - val_loss: 118.2082 - val_mse: 118.2082\n",
            "Epoch 932/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.5060 - mse: 93.5060 - val_loss: 89.7176 - val_mse: 89.7176\n",
            "Epoch 933/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 83.5968 - mse: 83.5968 - val_loss: 92.8493 - val_mse: 92.8493\n",
            "Epoch 934/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 87.0059 - mse: 87.0059 - val_loss: 91.9322 - val_mse: 91.9322\n",
            "Epoch 935/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 84.7747 - mse: 84.7747 - val_loss: 85.9535 - val_mse: 85.9535\n",
            "Epoch 936/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 93.0743 - mse: 93.0743 - val_loss: 92.8656 - val_mse: 92.8656\n",
            "Epoch 937/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 94.8369 - mse: 94.8369 - val_loss: 102.6830 - val_mse: 102.6830\n",
            "Epoch 938/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.0753 - mse: 92.0753 - val_loss: 89.9320 - val_mse: 89.9320\n",
            "Epoch 939/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 96.7604 - mse: 96.7604 - val_loss: 107.6815 - val_mse: 107.6815\n",
            "Epoch 940/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.1952 - mse: 90.1952 - val_loss: 85.8697 - val_mse: 85.8697\n",
            "Epoch 941/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.9917 - mse: 92.9917 - val_loss: 107.7822 - val_mse: 107.7822\n",
            "Epoch 942/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 95.2852 - mse: 95.2852 - val_loss: 87.4384 - val_mse: 87.4384\n",
            "Epoch 943/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.2160 - mse: 84.2160 - val_loss: 89.0784 - val_mse: 89.0784\n",
            "Epoch 944/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.3206 - mse: 85.3206 - val_loss: 85.8045 - val_mse: 85.8045\n",
            "Epoch 945/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.4526 - mse: 85.4526 - val_loss: 93.4441 - val_mse: 93.4441\n",
            "Epoch 946/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.5581 - mse: 84.5581 - val_loss: 86.5753 - val_mse: 86.5753\n",
            "Epoch 947/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 83.5417 - mse: 83.5417 - val_loss: 87.6908 - val_mse: 87.6908\n",
            "Epoch 948/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.3273 - mse: 81.3273 - val_loss: 89.2458 - val_mse: 89.2458\n",
            "Epoch 949/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.5776 - mse: 84.5776 - val_loss: 90.4885 - val_mse: 90.4885\n",
            "Epoch 950/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.2218 - mse: 83.2218 - val_loss: 91.1288 - val_mse: 91.1288\n",
            "Epoch 951/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.8244 - mse: 82.8244 - val_loss: 100.4156 - val_mse: 100.4156\n",
            "Epoch 952/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 91.2312 - mse: 91.2312 - val_loss: 89.0476 - val_mse: 89.0476\n",
            "Epoch 953/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.3425 - mse: 87.3425 - val_loss: 86.4858 - val_mse: 86.4858\n",
            "Epoch 954/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.1823 - mse: 82.1823 - val_loss: 97.2660 - val_mse: 97.2660\n",
            "Epoch 955/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.0019 - mse: 89.0019 - val_loss: 87.8975 - val_mse: 87.8975\n",
            "Epoch 956/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.8878 - mse: 81.8878 - val_loss: 87.1807 - val_mse: 87.1807\n",
            "Epoch 957/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.5096 - mse: 81.5096 - val_loss: 86.1374 - val_mse: 86.1374\n",
            "Epoch 958/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.0653 - mse: 81.0653 - val_loss: 90.8592 - val_mse: 90.8592\n",
            "Epoch 959/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.6140 - mse: 84.6140 - val_loss: 94.3352 - val_mse: 94.3352\n",
            "Epoch 960/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 95.0524 - mse: 95.0524 - val_loss: 131.0008 - val_mse: 131.0008\n",
            "Epoch 961/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.9616 - mse: 97.9616 - val_loss: 85.6460 - val_mse: 85.6460\n",
            "Epoch 962/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 89.1021 - mse: 89.1021 - val_loss: 102.0241 - val_mse: 102.0241\n",
            "Epoch 963/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 91.2471 - mse: 91.2471 - val_loss: 85.7663 - val_mse: 85.7663\n",
            "Epoch 964/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 96.0174 - mse: 96.0174 - val_loss: 108.8708 - val_mse: 108.8708\n",
            "Epoch 965/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 90.8507 - mse: 90.8507 - val_loss: 87.0585 - val_mse: 87.0585\n",
            "Epoch 966/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 92.0338 - mse: 92.0338 - val_loss: 97.7080 - val_mse: 97.7080\n",
            "Epoch 967/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 90.2294 - mse: 90.2294 - val_loss: 90.8245 - val_mse: 90.8245\n",
            "Epoch 968/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.1804 - mse: 85.1804 - val_loss: 85.1598 - val_mse: 85.1598\n",
            "Epoch 969/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.1400 - mse: 83.1400 - val_loss: 87.3263 - val_mse: 87.3263\n",
            "Epoch 970/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.5675 - mse: 83.5675 - val_loss: 88.8551 - val_mse: 88.8551\n",
            "Epoch 971/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 88.9711 - mse: 88.9711 - val_loss: 109.6183 - val_mse: 109.6183\n",
            "Epoch 972/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.0507 - mse: 95.0507 - val_loss: 102.6616 - val_mse: 102.6616\n",
            "Epoch 973/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 110.4745 - mse: 110.4745 - val_loss: 120.9557 - val_mse: 120.9557\n",
            "Epoch 974/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 95.3771 - mse: 95.3771 - val_loss: 88.9447 - val_mse: 88.9447\n",
            "Epoch 975/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.2240 - mse: 87.2240 - val_loss: 89.3531 - val_mse: 89.3531\n",
            "Epoch 976/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.3803 - mse: 82.3803 - val_loss: 85.4819 - val_mse: 85.4819\n",
            "Epoch 977/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.6300 - mse: 81.6300 - val_loss: 88.5728 - val_mse: 88.5728\n",
            "Epoch 978/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.8953 - mse: 82.8953 - val_loss: 86.1140 - val_mse: 86.1140\n",
            "Epoch 979/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.4585 - mse: 81.4585 - val_loss: 96.1398 - val_mse: 96.1398\n",
            "Epoch 980/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 97.0009 - mse: 97.0009 - val_loss: 96.8010 - val_mse: 96.8010\n",
            "Epoch 981/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.9123 - mse: 97.9123 - val_loss: 102.7867 - val_mse: 102.7867\n",
            "Epoch 982/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 97.6041 - mse: 97.6041 - val_loss: 88.0170 - val_mse: 88.0170\n",
            "Epoch 983/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 84.4348 - mse: 84.4348 - val_loss: 87.2914 - val_mse: 87.2914\n",
            "Epoch 984/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.5368 - mse: 80.5368 - val_loss: 86.1076 - val_mse: 86.1076\n",
            "Epoch 985/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.2367 - mse: 82.2367 - val_loss: 88.0129 - val_mse: 88.0129\n",
            "Epoch 986/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.4047 - mse: 82.4047 - val_loss: 87.5682 - val_mse: 87.5682\n",
            "Epoch 987/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.3462 - mse: 84.3462 - val_loss: 93.1925 - val_mse: 93.1925\n",
            "Epoch 988/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.9738 - mse: 85.9738 - val_loss: 92.9417 - val_mse: 92.9417\n",
            "Epoch 989/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 90.7538 - mse: 90.7538 - val_loss: 105.9840 - val_mse: 105.9840\n",
            "Epoch 990/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 91.1883 - mse: 91.1883 - val_loss: 97.7057 - val_mse: 97.7057\n",
            "Epoch 991/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 90.8776 - mse: 90.8776 - val_loss: 89.3521 - val_mse: 89.3521\n",
            "Epoch 992/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.0588 - mse: 84.0588 - val_loss: 97.0821 - val_mse: 97.0821\n",
            "Epoch 993/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.0376 - mse: 84.0376 - val_loss: 85.3544 - val_mse: 85.3544\n",
            "Epoch 994/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.1841 - mse: 83.1841 - val_loss: 86.7044 - val_mse: 86.7044\n",
            "Epoch 995/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 80.4571 - mse: 80.4571 - val_loss: 88.3628 - val_mse: 88.3628\n",
            "Epoch 996/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.3933 - mse: 84.3933 - val_loss: 98.8205 - val_mse: 98.8205\n",
            "Epoch 997/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.7629 - mse: 84.7629 - val_loss: 87.8590 - val_mse: 87.8590\n",
            "Epoch 998/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.1753 - mse: 84.1753 - val_loss: 97.8730 - val_mse: 97.8730\n",
            "Epoch 999/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 87.4589 - mse: 87.4589 - val_loss: 87.2871 - val_mse: 87.2871\n",
            "Epoch 1000/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 86.0621 - mse: 86.0621 - val_loss: 100.7660 - val_mse: 100.7660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MagVRw9qTw6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "aacf084a-7ecc-479d-dc6a-e035111e9ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.evaluate(X_test, y_test)\n",
        "print(model.metrics_names)\n",
        "metrics=[\"accuracy\"];\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLJaIeO0OTdd",
        "outputId": "ec80d80e-b839-442c-dd84-ced68242e393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 1ms/step - loss: 96.0224 - mse: 96.0224\n",
            "['loss', 'mse']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1839    256.77\n",
              "3128    269.66\n",
              "3483    273.21\n",
              "915     247.49\n",
              "3863    277.01\n",
              "         ...  \n",
              "1873    257.11\n",
              "1501    253.39\n",
              "471     242.88\n",
              "2684    265.22\n",
              "1805    256.43\n",
              "Name: elev, Length: 596, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "B1RT-igrT10L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHrRSkkH_CGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}